{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and MNIST set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: (784, 60000) (1, 60000)\n",
      "test set shape: (784, 10000) (1, 10000)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mlxtend.preprocessing import one_hot\n",
    "from scipy import ndimage\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "N_train_data = x_train.shape[0]\n",
    "N_test_data = x_test.shape[0]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "x_train = x_train.reshape(N_train_data, -1).T\n",
    "x_test = x_test.reshape(N_test_data, -1).T\n",
    "y_train = y_train.reshape((N_train_data, 1)).T\n",
    "y_test = y_test.reshape((N_test_data, 1)).T\n",
    "\n",
    "print (\"training set shape:\", x_train.shape, y_train.shape)\n",
    "print (\"test set shape:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8eabc4e5c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "def crop_center(img, cropx, cropy):\n",
    "    y, x = img.shape\n",
    "    startx = (x//2) - (cropx//2)\n",
    "    starty = (y//2) - (cropy//2)\n",
    "    return img[starty:starty+cropy, startx:startx+cropx]\n",
    "\n",
    "img = x_train[:,1].reshape((28,28))\n",
    "print(y_train[:,3])\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define or load a multi-layer perceptron (MLP) neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer_sizes = [784,20,10]\n",
    "#layer_sizes = [784,40,10]\n",
    "layer_sizes = [784,80,10]\n",
    "#layer_sizes = [784,200,10]\n",
    "#layer_sizes = [784,160,40,10]\n",
    "#layer_sizes = [784,200,60,20,10] # L2_regularization_rate = 0.01\n",
    "\n",
    "w = {i: np.random.rand(layer_sizes[i], layer_sizes[i-1]) * 2 -1 for i in range(1, len(layer_sizes))} # [0, 1) * 2 -1\n",
    "b = {i: np.random.rand(layer_sizes[i]).reshape((layer_sizes[i], 1)) * 2 -1 for i in range(1, len(layer_sizes))} # [0, 1) * 2 -1\n",
    "\n",
    "#layer_sizes, w, b = np.load(\"MLP 2019-02-24 10:21.npy\") # layer_sizes = [784, 20, 10] \ttest set accuracy = 0.9393\n",
    "#layer_sizes, w, b = np.load(\"MLP 2019-02-24 10:31.npy\") # layer_sizes = [784, 40, 10] \ttest set accuracy = 0.9477\n",
    "#layer_sizes, w, b = np.load(\"MLP 2019-03-07 21:52.npy\") # layer_sizes = [784, 80, 10] \ttest set accuracy = 0.9618\n",
    "#layer_sizes, w, b = np.load(\"MLP 2019-02-23 13:47.npy\") # layer_sizes = [784, 200, 10] \ttest set accuracy = 0.9491\n",
    "#layer_sizes, w, b = np.load(\"MLP 2019-02-23 12:44.npy\") # layer_sizes = [784, 160, 40, 10] \ttest set accuracy = 0.9472\n",
    "#layer_sizes, w, b = np.load(\"MLP 2019-02-24 09:18.npy\") # layer_sizes = [784, 200, 60, 20, 10] \ttest set accuracy = 0.9559\n",
    "\n",
    "N_layers = len(layer_sizes)\n",
    "assert(N_layers > 2)\n",
    "N_inputs = layer_sizes[0]\n",
    "N_outputs = layer_sizes[-1]\n",
    "input_layer = 0\n",
    "output_layer = N_layers - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear equation: $$z^l = w^l a^{l-1} + b^l, \\forall l \\neq 0$$\n",
    "ReLU activation function: $$a^l_i = \\max(z^l_i, 0), \\forall i, 0<l<output\\_layer$$\n",
    "Softmax function: $$p_i = \\frac{e^{z^L_i}}{\\Sigma_j e^{z^L_j}}, \\forall i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = dict()\n",
    "a = dict()\n",
    "def forward(x):\n",
    "    '''#print (\"== Forward ==\")'''\n",
    "    \n",
    "    for l in range(1, N_layers):\n",
    "        assert(not np.isnan(np.sum(w[l])))\n",
    "        assert(not np.isnan(np.sum(b[l])))\n",
    "    \n",
    "    a[0] = x # input layer\n",
    "    for l in range(1, output_layer): # hidden layers\n",
    "        z[l] = np.matmul(w[l], a[l-1]) + b[l]\n",
    "        assert(np.isfinite(np.sum(z[l])))\n",
    "        a[l] = np.maximum(z[l], 0) # ReLU\n",
    "        assert(np.isfinite(np.sum(a[l])))\n",
    "    z[output_layer] = np.matmul(w[output_layer], a[output_layer-1]) + b[output_layer] # output layer\n",
    "    assert(np.isfinite(np.sum(z[output_layer])))\n",
    "    \n",
    "    z[output_layer] = np.minimum(z[output_layer], 709) # force saturate\n",
    "    exps = np.exp(z[output_layer])\n",
    "    p = exps / np.sum(exps, axis=0) # softmax\n",
    "    assert(np.isfinite(np.sum(p)))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_sizes = [784, 80, 10] \ttest set accuracy = 0.9595\n"
     ]
    }
   ],
   "source": [
    "p = forward(x_test)\n",
    "y_ = np.argmax(p, axis=0).reshape((1, N_test_data))\n",
    "accuracy = np.sum(y_ == y_test) / N_test_data\n",
    "print (\"layer_sizes =\", layer_sizes, \"\\ttest set accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#npy_filename = \"MLP \"+datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "#np.save(npy_filename, [layer_sizes, w, b])\n",
    "#print ('save to', \"'\"+npy_filename+\".npy'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set shape: (784, 10000) (1, 10000)\n",
      "training set shape: (784, 50000) (10, 50000)\n"
     ]
    }
   ],
   "source": [
    "# split a validation set from training set\n",
    "x_valid = x_train[:, 0:10000]\n",
    "y_valid = y_train[:, 0:10000]\n",
    "x_train = x_train[:, 10000:60000]\n",
    "y_train = y_train[:, 10000:60000]\n",
    "\n",
    "N_training_data = y_train.shape[1]\n",
    "N_validation_data = y_valid.shape[1]\n",
    "\n",
    "y_train = one_hot(y_train[0]).T\n",
    "\n",
    "print (\"validation set shape:\", x_valid.shape, y_valid.shape)\n",
    "print (\"training set shape:\", x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corss entropy loss function: $$J = -\\sum_i (y_i \\ln p_i + (1-y_i) \\ln (1-p_i))$$\n",
    "Derivative of cross entropy loss function: $$\\frac{\\partial J}{\\partial p} = (\\frac{1}{1-y-p})^\\text{T} = dJdp$$\n",
    "Derivative of softmax: $$\\frac{\\partial p}{\\partial z^L} = \\text{diag}(p)-pp^\\text{T} = dpdz$$\n",
    "Derivative of ReLU activation function: $$\\text{diag}^{-1}(\\frac{\\partial a^l}{\\partial z^l}) = z^l > 0 ? 1:0 = diag\\_inv\\_dadz[l]$$\n",
    "Recursive formula by chain rule: \n",
    "$$\\frac{\\partial J}{\\partial z^L} = \\frac{\\partial J}{\\partial p} \\frac{\\partial p}{\\partial z^L} \\\\\n",
    "\\Rightarrow dJdz[last\\_layer] = dJdp \\times dpdz$$\n",
    "$$\\frac{\\partial J}{\\partial z^l} = (\\frac{\\partial J}{\\partial z^{l+1}} w^{l+1}) \\otimes {\\text{diag}^{-1}(\\frac{\\partial a^l}{\\partial z^l})}^\\text{T} \\\\\n",
    "\\Rightarrow dJdz[l] = (dJdz[l+1] \\times w[l+1]) \\otimes diag\\_inv\\_dadz[l]^\\text{T}$$\n",
    "Finally... \n",
    "$$\\frac{\\partial J}{\\partial w^l} = a^{l-1} \\frac{\\partial J}{\\partial z^l} = dJdw[l]$$\n",
    "$$\\frac{\\partial J}{\\partial b^l} = \\frac{\\partial J}{\\partial z^l} = dJdb[l]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(p, y):\n",
    "    '''#print (\"== Backward ==\")'''\n",
    "    \n",
    "    assert(np.isfinite(np.sum(p)))\n",
    "    assert(np.isfinite(np.sum(y)))\n",
    "    for l in range(1, output_layer):\n",
    "        assert(np.isfinite(np.sum(z[l])))\n",
    "        assert(np.isfinite(np.sum(a[l])))\n",
    "    assert(np.isfinite(np.sum(z[output_layer])))\n",
    "    assert(p.shape[0] == N_outputs and p.shape[1] == batch_size)\n",
    "    assert(y.shape[0] == N_outputs and y.shape[1] == batch_size)\n",
    "    assert((1-y-p).all() != 0) # p should not be too close to neither 1 or 0\n",
    "    \n",
    "    p = np.maximum(p, 1.0e-307) # force saturate\n",
    "    p = np.minimum(p, 1-1.0e-16) # force saturate\n",
    "    dJdp = (1.0 / (1-y-p)).T # derivative of cross entropy\n",
    "    assert(np.isfinite(np.sum(dJdp)))\n",
    "    dpdz = np.zeros((batch_size, N_outputs, N_outputs))\n",
    "    for i in range(batch_size):\n",
    "        dpdz[i] = np.diag(p[:,i]) - np.outer(p[:,i], p[:,i]) # derivative of softmax\n",
    "    assert(np.isfinite(np.sum(dpdz)))\n",
    "    diag_inv_dadz = {i: np.where(e>0, 1, 0).T for i, e in z.items()} # derivative of ReLU\n",
    "    \n",
    "    dJdz = dict()\n",
    "    dJdz[output_layer] = np.zeros((batch_size, N_outputs))\n",
    "    for i in range(batch_size):\n",
    "        dJdz[output_layer][i] = np.matmul(dJdp[i], dpdz[i])\n",
    "    assert(np.isfinite(np.sum(dJdz[output_layer])))\n",
    "    dJdw = dict()\n",
    "    dJdw[output_layer] = np.matmul(a[output_layer-1], dJdz[output_layer]) / batch_size\n",
    "    assert(np.isfinite(np.sum(dJdw[output_layer])))\n",
    "    dJdb = dict()\n",
    "    dJdb[output_layer] = np.average(dJdz[output_layer], axis=0).reshape((1, layer_sizes[output_layer]))\n",
    "    assert(np.isfinite(np.sum(dJdb[output_layer])))\n",
    "    \n",
    "    for l in range(output_layer-1, 0, -1):\n",
    "        dJdz[l] = np.matmul(dJdz[l+1], w[l+1]) * diag_inv_dadz[l]\n",
    "        assert(np.isfinite(np.sum(dJdz[l])))\n",
    "        dJdw[l] = np.matmul(a[l-1], dJdz[l]) / batch_size\n",
    "        assert(np.isfinite(np.sum(dJdw[l])))\n",
    "        dJdb[l] = np.average(dJdz[l], axis=0).reshape((1, layer_sizes[l]))\n",
    "        assert(np.isfinite(np.sum(dJdb[l])))\n",
    "    \n",
    "    return dJdw, dJdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_sizes = [784, 80, 10] \t#training data = 50000 \t#batches_per_epoch = 100\n",
      " 0 \ttraining set loss&accuracy: 212241 0.9706 \tvalidation set accuracy: 0.7871 .....................\n",
      " 1 \ttraining set loss&accuracy: 72670 0.9664 \tvalidation set accuracy: 0.8322 ......................\n",
      " 2 \ttraining set loss&accuracy: 54563 0.9645 \tvalidation set accuracy: 0.8519 ......................\n",
      " 3 \ttraining set loss&accuracy: 46087 0.9654 \tvalidation set accuracy: 0.8644 ......................\n",
      " 4 \ttraining set loss&accuracy: 41032 0.9657 \tvalidation set accuracy: 0.8746 ......................\n",
      " 5 \ttraining set loss&accuracy: 37600 0.9646 \tvalidation set accuracy: 0.8821 ......................\n",
      " 6 \ttraining set loss&accuracy: 35069 0.9644 \tvalidation set accuracy: 0.8864 ......................\n",
      " 7 \ttraining set loss&accuracy: 33101 0.9626 \tvalidation set accuracy: 0.8915 ......................\n",
      " 8 \ttraining set loss&accuracy: 31506 0.9623 \tvalidation set accuracy: 0.8954 ......................\n",
      " 9 \ttraining set loss&accuracy: 30165 0.9619 \tvalidation set accuracy: 0.8987 ......................\n",
      " 10 \ttraining set loss&accuracy: 29013 0.9632 \tvalidation set accuracy: 0.9014 .....................\n",
      " 11 \ttraining set loss&accuracy: 28005 0.9632 \tvalidation set accuracy: 0.9036 .....................\n",
      " 12 \ttraining set loss&accuracy: 27108 0.9632 \tvalidation set accuracy: 0.9054 .....................\n",
      " 13 \ttraining set loss&accuracy: 26305 0.9625 \tvalidation set accuracy: 0.9077 .....................\n",
      " 14 \ttraining set loss&accuracy: 25581 0.9616 \tvalidation set accuracy: 0.9106 .....................\n",
      " 15 \ttraining set loss&accuracy: 24918 0.9608 \tvalidation set accuracy: 0.9121 .....................\n",
      " 16 \ttraining set loss&accuracy: 24313 0.9609 \tvalidation set accuracy: 0.9133 .....................\n",
      " 17 \ttraining set loss&accuracy: 23753 0.9613 \tvalidation set accuracy: 0.9139 .....................\n",
      " 18 \ttraining set loss&accuracy: 23234 0.9612 \tvalidation set accuracy: 0.9154 .....................\n",
      " 19 \ttraining set loss&accuracy: 22750 0.9606 \tvalidation set accuracy: 0.9165 .....................\n",
      " 20 \ttraining set loss&accuracy: 22297 0.9604 \tvalidation set accuracy: 0.9176 .....................\n",
      " 21 \ttraining set loss&accuracy: 21871 0.9604 \tvalidation set accuracy: 0.9193 .....................\n",
      " 22 \ttraining set loss&accuracy: 21469 0.9603 \tvalidation set accuracy: 0.9213 .....................\n",
      " 23 \ttraining set loss&accuracy: 21091 0.9614 \tvalidation set accuracy: 0.9224 .....................\n",
      " 24 \ttraining set loss&accuracy: 20733 0.9616 \tvalidation set accuracy: 0.9228 .....................\n",
      " 25 \ttraining set loss&accuracy: 20395 0.9612 \tvalidation set accuracy: 0.9243 .....................\n",
      " 26 \ttraining set loss&accuracy: 20074 0.9616 \tvalidation set accuracy: 0.9258 .....................\n",
      " 27 \ttraining set loss&accuracy: 19768 0.9612 \tvalidation set accuracy: 0.9271 .....................\n",
      " 28 \ttraining set loss&accuracy: 19477 0.9607 \tvalidation set accuracy: 0.9276 .....................\n",
      " 29 \ttraining set loss&accuracy: 19199 0.9609 \tvalidation set accuracy: 0.9282 .....................\n",
      " 30 \ttraining set loss&accuracy: 18934 0.9604 \tvalidation set accuracy: 0.9292 .....................\n",
      " 31 \ttraining set loss&accuracy: 18678 0.9600 \tvalidation set accuracy: 0.9296 .....................\n",
      " 32 \ttraining set loss&accuracy: 18431 0.9602 \tvalidation set accuracy: 0.9306 .....................\n",
      " 33 \ttraining set loss&accuracy: 18194 0.9600 \tvalidation set accuracy: 0.9318 .....................\n",
      " 34 \ttraining set loss&accuracy: 17966 0.9600 \tvalidation set accuracy: 0.9319 .....................\n",
      " 35 \ttraining set loss&accuracy: 17745 0.9600 \tvalidation set accuracy: 0.9324 .....................\n",
      " 36 \ttraining set loss&accuracy: 17533 0.9598 \tvalidation set accuracy: 0.9328 .....................\n",
      " 37 \ttraining set loss&accuracy: 17328 0.9598 \tvalidation set accuracy: 0.9335 .....................\n",
      " 38 \ttraining set loss&accuracy: 17130 0.9592 \tvalidation set accuracy: 0.9346 .....................\n",
      " 39 \ttraining set loss&accuracy: 16936 0.9594 \tvalidation set accuracy: 0.9348 .....................\n",
      " 40 \ttraining set loss&accuracy: 16747 0.9589 \tvalidation set accuracy: 0.9350 .....................\n",
      " 41 \ttraining set loss&accuracy: 16563 0.9587 \tvalidation set accuracy: 0.9362 .....................\n",
      " 42 \ttraining set loss&accuracy: 16384 0.9585 \tvalidation set accuracy: 0.9367 .....................\n",
      " 43 \ttraining set loss&accuracy: 16209 0.9591 \tvalidation set accuracy: 0.9368 .....................\n",
      " 44 \ttraining set loss&accuracy: 16039 0.9585 \tvalidation set accuracy: 0.9369 .....................\n",
      " 45 \ttraining set loss&accuracy: 15873 0.9591 \tvalidation set accuracy: 0.9375 .....................\n",
      " 46 \ttraining set loss&accuracy: 15712 0.9593 \tvalidation set accuracy: 0.9381 .....................\n",
      " 47 \ttraining set loss&accuracy: 15555 0.9595 \tvalidation set accuracy: 0.9385 .....................\n",
      " 48 \ttraining set loss&accuracy: 15401 0.9593 \tvalidation set accuracy: 0.9394 .....................\n",
      " 49 \ttraining set loss&accuracy: 15251 0.9595 \tvalidation set accuracy: 0.9397 .....................\n",
      " 50 \ttraining set loss&accuracy: 15103 0.9591 \tvalidation set accuracy: 0.9403 .....................\n",
      " 51 \ttraining set loss&accuracy: 14958 0.9595 \tvalidation set accuracy: 0.9405 .....................\n",
      " 52 \ttraining set loss&accuracy: 14816 0.9595 \tvalidation set accuracy: 0.9410 .....................\n",
      " 53 \ttraining set loss&accuracy: 14677 0.9595 \tvalidation set accuracy: 0.9416 .....................\n",
      " 54 \ttraining set loss&accuracy: 14541 0.9592 \tvalidation set accuracy: 0.9420 .....................\n",
      " 55 \ttraining set loss&accuracy: 14409 0.9592 \tvalidation set accuracy: 0.9424 .....................\n",
      " 56 \ttraining set loss&accuracy: 14279 0.9594 \tvalidation set accuracy: 0.9430 .....................\n",
      " 57 \ttraining set loss&accuracy: 14152 0.9592 \tvalidation set accuracy: 0.9434 .....................\n",
      " 58 \ttraining set loss&accuracy: 14027 0.9592 \tvalidation set accuracy: 0.9438 .....................\n",
      " 59 \ttraining set loss&accuracy: 13906 0.9592 \tvalidation set accuracy: 0.9441 .....................\n",
      " 60 \ttraining set loss&accuracy: 13787 0.9590 \tvalidation set accuracy: 0.9444 .....................\n",
      " 61 \ttraining set loss&accuracy: 13669 0.9588 \tvalidation set accuracy: 0.9444 .....................\n",
      " 62 \ttraining set loss&accuracy: 13554 0.9588 \tvalidation set accuracy: 0.9446 .....................\n",
      " 63 \ttraining set loss&accuracy: 13441 0.9586 \tvalidation set accuracy: 0.9449 .....................\n",
      " 64 \ttraining set loss&accuracy: 13330 0.9588 \tvalidation set accuracy: 0.9453 .....................\n",
      " 65 \ttraining set loss&accuracy: 13221 0.9590 \tvalidation set accuracy: 0.9453 .....................\n",
      " 66 \ttraining set loss&accuracy: 13115 0.9590 \tvalidation set accuracy: 0.9453 .....................\n",
      " 67 \ttraining set loss&accuracy: 13010 0.9586 \tvalidation set accuracy: 0.9456 .....................\n",
      " 68 \ttraining set loss&accuracy: 12907 0.9592 \tvalidation set accuracy: 0.9456 .....................\n",
      " 69 \ttraining set loss&accuracy: 12806 0.9591 \tvalidation set accuracy: 0.9460 .....................\n",
      " 70 \ttraining set loss&accuracy: 12705 0.9593 \tvalidation set accuracy: 0.9463 .....................\n",
      " 71 \ttraining set loss&accuracy: 12607 0.9593 \tvalidation set accuracy: 0.9462 .....................\n",
      " 72 \ttraining set loss&accuracy: 12511 0.9594 \tvalidation set accuracy: 0.9465 .....................\n",
      " 73 \ttraining set loss&accuracy: 12416 0.9598 \tvalidation set accuracy: 0.9471 .....................\n",
      " 74 \ttraining set loss&accuracy: 12323 0.9598 \tvalidation set accuracy: 0.9472 .....................\n",
      " 75 \ttraining set loss&accuracy: 12231 0.9601 \tvalidation set accuracy: 0.9473 .....................\n",
      " 76 \ttraining set loss&accuracy: 12141 0.9601 \tvalidation set accuracy: 0.9474 .....................\n",
      " 77 \ttraining set loss&accuracy: 12053 0.9601 \tvalidation set accuracy: 0.9475 .....................\n",
      " 78 \ttraining set loss&accuracy: 11966 0.9603 \tvalidation set accuracy: 0.9477 .....................\n",
      " 79 \ttraining set loss&accuracy: 11879 0.9607 \tvalidation set accuracy: 0.9479 .....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80 \ttraining set loss&accuracy: 11795 0.9607 \tvalidation set accuracy: 0.9484 .....................\n",
      " 81 \ttraining set loss&accuracy: 11712 0.9608 \tvalidation set accuracy: 0.9488 .....................\n",
      " 82 \ttraining set loss&accuracy: 11630 0.9610 \tvalidation set accuracy: 0.9493 .....................\n",
      " 83 \ttraining set loss&accuracy: 11550 0.9608 \tvalidation set accuracy: 0.9493 .....................\n",
      " 84 \ttraining set loss&accuracy: 11471 0.9607 \tvalidation set accuracy: 0.9495 .....................\n",
      " 85 \ttraining set loss&accuracy: 11394 0.9609 \tvalidation set accuracy: 0.9493 .....................\n",
      " 86 \ttraining set loss&accuracy: 11317 0.9607 \tvalidation set accuracy: 0.9494 .....................\n",
      " 87 \ttraining set loss&accuracy: 11242 0.9607 \tvalidation set accuracy: 0.9494 .....................\n",
      " 88 \ttraining set loss&accuracy: 11168 0.9609 \tvalidation set accuracy: 0.9497 .....................\n",
      " 89 \ttraining set loss&accuracy: 11095 0.9609 \tvalidation set accuracy: 0.9498 .....................\n",
      " 90 \ttraining set loss&accuracy: 11022 0.9613 \tvalidation set accuracy: 0.9500 .....................\n",
      " 91 \ttraining set loss&accuracy: 10950 0.9611 \tvalidation set accuracy: 0.9501 .....................\n",
      " 92 \ttraining set loss&accuracy: 10879 0.9606 \tvalidation set accuracy: 0.9504 .....................\n",
      " 93 \ttraining set loss&accuracy: 10810 0.9606 \tvalidation set accuracy: 0.9505 .....................\n",
      " 94 \ttraining set loss&accuracy: 10741 0.9604 \tvalidation set accuracy: 0.9508 .....................\n",
      " 95 \ttraining set loss&accuracy: 10674 0.9604 \tvalidation set accuracy: 0.9510 .....................\n",
      " 96 \ttraining set loss&accuracy: 10607 0.9606 \tvalidation set accuracy: 0.9511 .....................\n",
      " 97 \ttraining set loss&accuracy: 10541 0.9604 \tvalidation set accuracy: 0.9513 .....................\n",
      " 98 \ttraining set loss&accuracy: 10475 0.9606 \tvalidation set accuracy: 0.9514 .....................\n",
      " 99 \ttraining set loss&accuracy: 10411 0.9606 \tvalidation set accuracy: 0.9516 .....................\n",
      " 100 \ttraining set loss&accuracy: 10347 0.9606 \tvalidation set accuracy: 0.9517 ....................\n",
      " 101 \ttraining set loss&accuracy: 10283 0.9608 \tvalidation set accuracy: 0.9522 ....................\n",
      " 102 \ttraining set loss&accuracy: 10221 0.9610 \tvalidation set accuracy: 0.9524 ....................\n",
      " 103 \ttraining set loss&accuracy: 10159 0.9608 \tvalidation set accuracy: 0.9522 ....................\n",
      " 104 \ttraining set loss&accuracy: 10098 0.9608 \tvalidation set accuracy: 0.9523 ....................\n",
      " 105 \ttraining set loss&accuracy: 10038 0.9608 \tvalidation set accuracy: 0.9525 ....................\n",
      " 106 \ttraining set loss&accuracy: 9978 0.9608 \tvalidation set accuracy: 0.9528 .....................\n",
      " 107 \ttraining set loss&accuracy: 9918 0.9606 \tvalidation set accuracy: 0.9530 .....................\n",
      " 108 \ttraining set loss&accuracy: 9860 0.9607 \tvalidation set accuracy: 0.9531 .....................\n",
      " 109 \ttraining set loss&accuracy: 9802 0.9603 \tvalidation set accuracy: 0.9532 .....................\n",
      " 110 \ttraining set loss&accuracy: 9745 0.9603 \tvalidation set accuracy: 0.9532 .....................\n",
      " 111 \ttraining set loss&accuracy: 9688 0.9599 \tvalidation set accuracy: 0.9537 .....................\n",
      " 112 \ttraining set loss&accuracy: 9632 0.9601 \tvalidation set accuracy: 0.9539 .....................\n",
      " 113 \ttraining set loss&accuracy: 9576 0.9599 \tvalidation set accuracy: 0.9538 .....................\n",
      " 114 \ttraining set loss&accuracy: 9521 0.9601 \tvalidation set accuracy: 0.9539 .....................\n",
      " 115 \ttraining set loss&accuracy: 9466 0.9599 \tvalidation set accuracy: 0.9537 .....................\n",
      " 116 \ttraining set loss&accuracy: 9412 0.9597 \tvalidation set accuracy: 0.9540 .....................\n",
      " 117 \ttraining set loss&accuracy: 9360 0.9595 \tvalidation set accuracy: 0.9540 .....................\n",
      " 118 \ttraining set loss&accuracy: 9307 0.9595 \tvalidation set accuracy: 0.9542 .....................\n",
      " 119 \ttraining set loss&accuracy: 9256 0.9596 \tvalidation set accuracy: 0.9543 .....................\n",
      " 120 \ttraining set loss&accuracy: 9204 0.9596 \tvalidation set accuracy: 0.9543 .....................\n",
      " 121 \ttraining set loss&accuracy: 9154 0.9596 \tvalidation set accuracy: 0.9545 .....................\n",
      " 122 \ttraining set loss&accuracy: 9103 0.9595 \tvalidation set accuracy: 0.9545 .....................\n",
      " 123 \ttraining set loss&accuracy: 9053 0.9597 ......................................................\tvalidation set accuracy: 0.9544 \n",
      " 124 \ttraining set loss&accuracy: 9004 0.9597 \tvalidation set accuracy: 0.9546 .....................\n",
      " 125 \ttraining set loss&accuracy: 8955 0.9597 \tvalidation set accuracy: 0.9549 .....................\n",
      " 126 \ttraining set loss&accuracy: 8907 0.9594 \tvalidation set accuracy: 0.9551 .....................\n",
      " 127 \ttraining set loss&accuracy: 8859 0.9595 \tvalidation set accuracy: 0.9550 .....................\n",
      " 128 \ttraining set loss&accuracy: 8811 0.9596 \tvalidation set accuracy: 0.9551 .....................\n",
      " 129 \ttraining set loss&accuracy: 8764 0.9600 \tvalidation set accuracy: 0.9551 .....................\n",
      " 130 \ttraining set loss&accuracy: 8718 0.9600 \tvalidation set accuracy: 0.9552 .....................\n",
      " 131 \ttraining set loss&accuracy: 8671 0.9600 \tvalidation set accuracy: 0.9553 .....................\n",
      " 132 \ttraining set loss&accuracy: 8625 0.9602 \tvalidation set accuracy: 0.9555 .....................\n",
      " 133 \ttraining set loss&accuracy: 8580 0.9602 \tvalidation set accuracy: 0.9559 .....................\n",
      " 134 \ttraining set loss&accuracy: 8535 0.9602 \tvalidation set accuracy: 0.9560 .....................\n",
      " 135 \ttraining set loss&accuracy: 8490 0.9602 \tvalidation set accuracy: 0.9559 .....................\n",
      " 136 \ttraining set loss&accuracy: 8446 0.9606 \tvalidation set accuracy: 0.9558 .....................\n",
      " 137 \ttraining set loss&accuracy: 8402 0.9604 \tvalidation set accuracy: 0.9559 .....................\n",
      " 138 \ttraining set loss&accuracy: 8358 0.9604 \tvalidation set accuracy: 0.9559 .....................\n",
      " 139 \ttraining set loss&accuracy: 8315 0.9602 \tvalidation set accuracy: 0.9560 .....................\n",
      " 140 \ttraining set loss&accuracy: 8272 0.9604 \tvalidation set accuracy: 0.9559 .....................\n",
      " 141 \ttraining set loss&accuracy: 8229 0.9600 \tvalidation set accuracy: 0.9559 .....................\n",
      " 142 \ttraining set loss&accuracy: 8187 0.9599 \tvalidation set accuracy: 0.9558 .....................\n",
      " 143 \ttraining set loss&accuracy: 8145 0.9597 \tvalidation set accuracy: 0.9559 .....................\n",
      " 144 \ttraining set loss&accuracy: 8103 0.9597 \tvalidation set accuracy: 0.9559 .....................\n",
      " 145 \ttraining set loss&accuracy: 8062 0.9596 \tvalidation set accuracy: 0.9560 .....................\n",
      " 146 \ttraining set loss&accuracy: 8020 0.9596 \tvalidation set accuracy: 0.9560 .....................\n",
      " 147 \ttraining set loss&accuracy: 7979 0.9596 \tvalidation set accuracy: 0.9562 .....................\n",
      " 148 \ttraining set loss&accuracy: 7938 0.9596 \tvalidation set accuracy: 0.9562 .....................\n",
      " 149 \ttraining set loss&accuracy: 7897 0.9594 \tvalidation set accuracy: 0.9562 .....................\n",
      " 150 \ttraining set loss&accuracy: 7856 0.9594 \tvalidation set accuracy: 0.9565 .....................\n",
      " 151 \ttraining set loss&accuracy: 7816 0.9594 \tvalidation set accuracy: 0.9564 .....................\n",
      " 152 \ttraining set loss&accuracy: 7775 0.9596 \tvalidation set accuracy: 0.9564 .....................\n",
      " 153 \ttraining set loss&accuracy: 7736 0.9594 \tvalidation set accuracy: 0.9566 .....................\n",
      " 154 \ttraining set loss&accuracy: 7696 0.9594 \tvalidation set accuracy: 0.9568 .....................\n",
      " 155 \ttraining set loss&accuracy: 7657 0.9594 \tvalidation set accuracy: 0.9569 .....................\n",
      " 156 \ttraining set loss&accuracy: 7619 0.9594 \tvalidation set accuracy: 0.9568 .....................\n",
      " 157 \ttraining set loss&accuracy: 7580 0.9594 \tvalidation set accuracy: 0.9570 .....................\n",
      " 158 \ttraining set loss&accuracy: 7542 0.9594 \tvalidation set accuracy: 0.9569 .....................\n",
      " 159 \ttraining set loss&accuracy: 7504 0.9594 \tvalidation set accuracy: 0.9570 .....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 160 \ttraining set loss&accuracy: 7467 0.9594 \tvalidation set accuracy: 0.9572 .....................\n",
      " 161 \ttraining set loss&accuracy: 7428 0.9596 \tvalidation set accuracy: 0.9570 .....................\n",
      " 162 \ttraining set loss&accuracy: 7391 0.9596 \tvalidation set accuracy: 0.9570 .....................\n",
      " 163 \ttraining set loss&accuracy: 7354 0.9596 \tvalidation set accuracy: 0.9567 .....................\n",
      " 164 \ttraining set loss&accuracy: 7317 0.9596 \tvalidation set accuracy: 0.9566 .....................\n",
      " 165 \ttraining set loss&accuracy: 7280 0.9596 \tvalidation set accuracy: 0.9565 .....................\n",
      " 166 \ttraining set loss&accuracy: 7244 0.9596 \tvalidation set accuracy: 0.9566 .....................\n",
      " 167 \ttraining set loss&accuracy: 7209 0.9598 \tvalidation set accuracy: 0.9567 .....................\n",
      " 168 \ttraining set loss&accuracy: 7172 0.9598 \tvalidation set accuracy: 0.9565 .....................\n",
      " 169 \ttraining set loss&accuracy: 7137 0.9599 \tvalidation set accuracy: 0.9565 .....................\n",
      " 170 \ttraining set loss&accuracy: 7102 0.9601 \tvalidation set accuracy: 0.9565 .....................\n",
      " 171 \ttraining set loss&accuracy: 7067 0.9599 \tvalidation set accuracy: 0.9567 .....................\n",
      " 172 \ttraining set loss&accuracy: 7032 0.9601 \tvalidation set accuracy: 0.9567 .....................\n",
      " 173 \ttraining set loss&accuracy: 6998 0.9599 \tvalidation set accuracy: 0.9567 .....................\n",
      " 174 \ttraining set loss&accuracy: 6964 0.9600 \tvalidation set accuracy: 0.9569 .....................\n",
      " 175 \ttraining set loss&accuracy: 6929 0.9600 \tvalidation set accuracy: 0.9569 .....................\n",
      " 176 \ttraining set loss&accuracy: 6896 0.9600 \tvalidation set accuracy: 0.9570 .....................\n",
      " 177 \ttraining set loss&accuracy: 6862 0.9599 \tvalidation set accuracy: 0.9571 .....................\n",
      " 178 \ttraining set loss&accuracy: 6829 0.9596 \tvalidation set accuracy: 0.9572 .....................\n",
      " 179 \ttraining set loss&accuracy: 6795 0.9594 \tvalidation set accuracy: 0.9572 .....................\n",
      " 180 \ttraining set loss&accuracy: 6762 0.9594 \tvalidation set accuracy: 0.9571 .....................\n",
      " 181 \ttraining set loss&accuracy: 6729 0.9594 \tvalidation set accuracy: 0.9571 .....................\n",
      " 182 \ttraining set loss&accuracy: 6697 0.9596 \tvalidation set accuracy: 0.9573 .....................\n",
      " 183 \ttraining set loss&accuracy: 6665 0.9596 \tvalidation set accuracy: 0.9573 .....................\n",
      " 184 \ttraining set loss&accuracy: 6633 0.9594 \tvalidation set accuracy: 0.9573 .....................\n",
      " 185 \ttraining set loss&accuracy: 6601 0.9593 \tvalidation set accuracy: 0.9574 .....................\n",
      " 186 \ttraining set loss&accuracy: 6570 0.9593 \tvalidation set accuracy: 0.9571 .....................\n",
      " 187 \ttraining set loss&accuracy: 6537 0.9594 \tvalidation set accuracy: 0.9571 .....................\n",
      " 188 \ttraining set loss&accuracy: 6507 0.9594 \tvalidation set accuracy: 0.9572 .....................\n",
      " 189 \ttraining set loss&accuracy: 6475 0.9594 \tvalidation set accuracy: 0.9571 .....................\n",
      " 190 \ttraining set loss&accuracy: 6445 0.9593 \tvalidation set accuracy: 0.9572 .....................\n",
      " 191 \ttraining set loss&accuracy: 6414 0.9593 \tvalidation set accuracy: 0.9573 .....................\n",
      " 192 \ttraining set loss&accuracy: 6384 0.9592 \tvalidation set accuracy: 0.9572 .....................\n",
      " 193 \ttraining set loss&accuracy: 6354 0.9594 \tvalidation set accuracy: 0.9573 .....................\n",
      " 194 \ttraining set loss&accuracy: 6324 0.9594 \tvalidation set accuracy: 0.9573 .....................\n",
      " 195 \ttraining set loss&accuracy: 6295 0.9594 \tvalidation set accuracy: 0.9573 .....................\n",
      " 196 \ttraining set loss&accuracy: 6265 0.9594 \tvalidation set accuracy: 0.9573 .....................\n",
      " 197 \ttraining set loss&accuracy: 6236 0.9594 \tvalidation set accuracy: 0.9574 .....................\n",
      " 198 \ttraining set loss&accuracy: 6207 0.9594 \tvalidation set accuracy: 0.9573 .....................\n",
      " 199 \ttraining set loss&accuracy: 6178 0.9594 \tvalidation set accuracy: 0.9573 .....................\n",
      " 200 \ttraining set loss&accuracy: 6149 0.9594 \tvalidation set accuracy: 0.9574 .....................\n",
      " 201 \ttraining set loss&accuracy: 6121 0.9594 \tvalidation set accuracy: 0.9575 .....................\n",
      " 202 \ttraining set loss&accuracy: 6093 0.9594 \tvalidation set accuracy: 0.9575 .....................\n",
      " 203 \ttraining set loss&accuracy: 6064 0.9594 \tvalidation set accuracy: 0.9576 .....................\n",
      " 204 \ttraining set loss&accuracy: 6037 0.9594 \tvalidation set accuracy: 0.9576 .....................\n",
      " 205 \ttraining set loss&accuracy: 6009 0.9596 \tvalidation set accuracy: 0.9577 .....................\n",
      " 206 \ttraining set loss&accuracy: 5981 0.9594 \tvalidation set accuracy: 0.9577 .....................\n",
      " 207 \ttraining set loss&accuracy: 5954 0.9592 \tvalidation set accuracy: 0.9577 .....................\n",
      " 208 \ttraining set loss&accuracy: 5927 0.9594 \tvalidation set accuracy: 0.9577 .....................\n",
      " 209 \ttraining set loss&accuracy: 5900 0.9594 \tvalidation set accuracy: 0.9578 .....................\n",
      " 210 \ttraining set loss&accuracy: 5873 0.9594 \tvalidation set accuracy: 0.9579 .....................\n",
      " 211 \ttraining set loss&accuracy: 5846 0.9592 \tvalidation set accuracy: 0.9580 .....................\n",
      " 212 \ttraining set loss&accuracy: 5820 0.9592 \tvalidation set accuracy: 0.9581 .....................\n",
      " 213 \ttraining set loss&accuracy: 5793 0.9591 \tvalidation set accuracy: 0.9583 .....................\n",
      " 214 \ttraining set loss&accuracy: 5767 0.9591 \tvalidation set accuracy: 0.9585 .....................\n",
      " 215 \ttraining set loss&accuracy: 5741 0.9591 \tvalidation set accuracy: 0.9585 .....................\n",
      " 216 \ttraining set loss&accuracy: 5715 0.9590 \tvalidation set accuracy: 0.9586 .....................\n",
      " 217 \ttraining set loss&accuracy: 5689 0.9590 \tvalidation set accuracy: 0.9586 .....................\n",
      " 218 \ttraining set loss&accuracy: 5664 0.9590 \tvalidation set accuracy: 0.9587 .....................\n",
      " 219 \ttraining set loss&accuracy: 5638 0.9590 \tvalidation set accuracy: 0.9587 .....................\n",
      " 220 \ttraining set loss&accuracy: 5613 0.9590 \tvalidation set accuracy: 0.9586 .....................\n",
      " 221 \ttraining set loss&accuracy: 5587 0.9592 \tvalidation set accuracy: 0.9586 .....................\n",
      " 222 \ttraining set loss&accuracy: 5562 0.9592 \tvalidation set accuracy: 0.9588 .....................\n",
      " 223 \ttraining set loss&accuracy: 5538 0.9592 \tvalidation set accuracy: 0.9590 .....................\n",
      " 224 \ttraining set loss&accuracy: 5512 0.9593 \tvalidation set accuracy: 0.9589 .....................\n",
      " 225 \ttraining set loss&accuracy: 5488 0.9593 \tvalidation set accuracy: 0.9590 .....................\n",
      " 226 \ttraining set loss&accuracy: 5463 0.9593 \tvalidation set accuracy: 0.9590 .....................\n",
      " 227 \ttraining set loss&accuracy: 5439 0.9595 \tvalidation set accuracy: 0.9590 .....................\n",
      " 228 \ttraining set loss&accuracy: 5414 0.9595 \tvalidation set accuracy: 0.9590 .....................\n",
      " 229 \ttraining set loss&accuracy: 5390 0.9597 \tvalidation set accuracy: 0.9590 .....................\n",
      " 230 \ttraining set loss&accuracy: 5366 0.9597 \tvalidation set accuracy: 0.9593 .....................\n",
      " 231 \ttraining set loss&accuracy: 5343 0.9597 \tvalidation set accuracy: 0.9591 .....................\n",
      " 232 \ttraining set loss&accuracy: 5319 0.9597 \tvalidation set accuracy: 0.9592 .....................\n",
      " 233 \ttraining set loss&accuracy: 5295 0.9597 \tvalidation set accuracy: 0.9592 .....................\n",
      " 234 \ttraining set loss&accuracy: 5271 0.9597 \tvalidation set accuracy: 0.9592 .....................\n",
      " 235 \ttraining set loss&accuracy: 5248 0.9597 \tvalidation set accuracy: 0.9591 .....................\n",
      " 236 \ttraining set loss&accuracy: 5224 0.9599 \tvalidation set accuracy: 0.9591 .....................\n",
      " 237 \ttraining set loss&accuracy: 5201 0.9599 \tvalidation set accuracy: 0.9591 .....................\n",
      " 238 \ttraining set loss&accuracy: 5178 0.9599 \tvalidation set accuracy: 0.9591 .....................\n",
      " 239 \ttraining set loss&accuracy: 5155 0.9597 \tvalidation set accuracy: 0.9592 .....................\n",
      " 240 \ttraining set loss&accuracy: 5132 0.9597 \tvalidation set accuracy: 0.9592 .....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 241 \ttraining set loss&accuracy: 5110 0.9597 \tvalidation set accuracy: 0.9591 .....................\n",
      " 242 \ttraining set loss&accuracy: 5086 0.9597 \tvalidation set accuracy: 0.9593 .....................\n",
      " 243 \ttraining set loss&accuracy: 5064 0.9597 \tvalidation set accuracy: 0.9592 .....................\n",
      " 244 \ttraining set loss&accuracy: 5041 0.9597 \tvalidation set accuracy: 0.9593 .....................\n",
      " 245 \ttraining set loss&accuracy: 5019 0.9596 \tvalidation set accuracy: 0.9593 .....................\n",
      " 246 \ttraining set loss&accuracy: 4997 0.9596 \tvalidation set accuracy: 0.9595 .....................\n",
      " 247 \ttraining set loss&accuracy: 4975 0.9598 \tvalidation set accuracy: 0.9595 .....................\n",
      " 248 \ttraining set loss&accuracy: 4953 0.9598 \tvalidation set accuracy: 0.9596 .....................\n",
      " 249 \ttraining set loss&accuracy: 4931 0.9598 \tvalidation set accuracy: 0.9596 .....................\n",
      " 250 \ttraining set loss&accuracy: 4909 0.9598 \tvalidation set accuracy: 0.9594 .....................\n",
      " 251 \ttraining set loss&accuracy: 4888 0.9598 \tvalidation set accuracy: 0.9595 .....................\n",
      " 252 \ttraining set loss&accuracy: 4866 0.9598 \tvalidation set accuracy: 0.9597 .....................\n",
      " 253 \ttraining set loss&accuracy: 4844 0.9598 \tvalidation set accuracy: 0.9598 .....................\n",
      " 254 \ttraining set loss&accuracy: 4823 0.9598 \tvalidation set accuracy: 0.9600 .....................\n",
      " 255 \ttraining set loss&accuracy: 4802 0.9598 \tvalidation set accuracy: 0.9598 .....................\n",
      " 256 \ttraining set loss&accuracy: 4781 0.9598 \tvalidation set accuracy: 0.9597 .....................\n",
      " 257 \ttraining set loss&accuracy: 4760 0.9600 \tvalidation set accuracy: 0.9596 .....................\n",
      " 258 \ttraining set loss&accuracy: 4740 0.9598 \tvalidation set accuracy: 0.9599 .....................\n",
      " 259 \ttraining set loss&accuracy: 4719 0.9598 \tvalidation set accuracy: 0.9597 .....................\n",
      " 260 \ttraining set loss&accuracy: 4699 0.9596 \tvalidation set accuracy: 0.9596 .....................\n",
      " 261 \ttraining set loss&accuracy: 4678 0.9598 \tvalidation set accuracy: 0.9597 .....................\n",
      " 262 \ttraining set loss&accuracy: 4658 0.9598 \tvalidation set accuracy: 0.9596 .....................\n",
      " 263 \ttraining set loss&accuracy: 4638 0.9598 \tvalidation set accuracy: 0.9595 .....................\n",
      " 264 \ttraining set loss&accuracy: 4617 0.9598 \tvalidation set accuracy: 0.9595 .....................\n",
      " 265 \ttraining set loss&accuracy: 4597 0.9598 \tvalidation set accuracy: 0.9594 .....................\n",
      " 266 \ttraining set loss&accuracy: 4577 0.9600 \tvalidation set accuracy: 0.9596 .....................\n",
      " 267 \ttraining set loss&accuracy: 4557 0.9598 \tvalidation set accuracy: 0.9597 .....................\n",
      " 268 \ttraining set loss&accuracy: 4538 0.9600 \tvalidation set accuracy: 0.9598 .....................\n",
      " 269 \ttraining set loss&accuracy: 4517 0.9600 \tvalidation set accuracy: 0.9596 .....................\n",
      " 270 \ttraining set loss&accuracy: 4498 0.9600 \tvalidation set accuracy: 0.9597 .....................\n",
      " 271 \ttraining set loss&accuracy: 4478 0.9600 \tvalidation set accuracy: 0.9597 .....................\n",
      " 272 \ttraining set loss&accuracy: 4459 0.9600 \tvalidation set accuracy: 0.9598 .....................\n",
      " 273 \ttraining set loss&accuracy: 4440 0.9600 \tvalidation set accuracy: 0.9598 .....................\n",
      " 274 \ttraining set loss&accuracy: 4420 0.9598 \tvalidation set accuracy: 0.9600 .....................\n",
      " 275 \ttraining set loss&accuracy: 4401 0.9598 \tvalidation set accuracy: 0.9600 .....................\n",
      " 276 \ttraining set loss&accuracy: 4382 0.9598 \tvalidation set accuracy: 0.9600 .....................\n",
      " 277 \ttraining set loss&accuracy: 4363 0.9598 \tvalidation set accuracy: 0.9599 .....................\n",
      " 278 \ttraining set loss&accuracy: 4345 0.9596 \tvalidation set accuracy: 0.9600 .....................\n",
      " 279 \ttraining set loss&accuracy: 4326 0.9596 \tvalidation set accuracy: 0.9599 .....................\n",
      " 280 \ttraining set loss&accuracy: 4307 0.9596 \tvalidation set accuracy: 0.9598 .....................\n",
      " 281 \ttraining set loss&accuracy: 4289 0.9596 \tvalidation set accuracy: 0.9597 .....................\n",
      " 282 \ttraining set loss&accuracy: 4270 0.9596 \tvalidation set accuracy: 0.9597 .....................\n",
      " 283 \ttraining set loss&accuracy: 4252 0.9597 \tvalidation set accuracy: 0.9597 .....................\n",
      " 284 \ttraining set loss&accuracy: 4234 0.9597 \tvalidation set accuracy: 0.9596 .....................\n",
      " 285 \ttraining set loss&accuracy: 4216 0.9598 \tvalidation set accuracy: 0.9596 .....................\n",
      " 286 \ttraining set loss&accuracy: 4197 0.9597 \tvalidation set accuracy: 0.9596 .....................\n",
      " 287 \ttraining set loss&accuracy: 4180 0.9597 \tvalidation set accuracy: 0.9595 .....................\n",
      " 288 \ttraining set loss&accuracy: 4162 0.9597 \tvalidation set accuracy: 0.9594 .....................\n",
      " 289 \ttraining set loss&accuracy: 4143 0.9597 \tvalidation set accuracy: 0.9594 .....................\n",
      " 290 \ttraining set loss&accuracy: 4126 0.9597 \tvalidation set accuracy: 0.9594 .....................\n",
      " 291 \ttraining set loss&accuracy: 4108 0.9597 \tvalidation set accuracy: 0.9593 .....................\n",
      " 292 \ttraining set loss&accuracy: 4091 0.9597 \tvalidation set accuracy: 0.9592 .....................\n",
      " 293 \ttraining set loss&accuracy: 4073 0.9597 \tvalidation set accuracy: 0.9592 .....................\n",
      " 294 \ttraining set loss&accuracy: 4056 0.9597 \tvalidation set accuracy: 0.9593 .....................\n",
      " 295 \ttraining set loss&accuracy: 4039 0.9597 \tvalidation set accuracy: 0.9593 .....................\n",
      " 296 \ttraining set loss&accuracy: 4022 0.9597 \tvalidation set accuracy: 0.9592 .....................\n",
      " 297 \ttraining set loss&accuracy: 4004 0.9597 \tvalidation set accuracy: 0.9593 .....................\n",
      " 298 \ttraining set loss&accuracy: 3988 0.9597 \tvalidation set accuracy: 0.9593 .....................\n",
      " 299 \ttraining set loss&accuracy: 3971 0.9597 \tvalidation set accuracy: 0.9593 .....................\n",
      " 300 \ttraining set loss&accuracy: 3954 0.9597 \tvalidation set accuracy: 0.9593 .....................\n",
      " 301 \ttraining set loss&accuracy: 3937 0.9596 \tvalidation set accuracy: 0.9594 .....................\n",
      " 302 \ttraining set loss&accuracy: 3921 0.9598 \tvalidation set accuracy: 0.9593 .....................\n",
      " 303 \ttraining set loss&accuracy: 3904 0.9596 \tvalidation set accuracy: 0.9594 .....................\n",
      " 304 \ttraining set loss&accuracy: 3888 0.9596 \tvalidation set accuracy: 0.9593 .....................\n",
      " 305 \ttraining set loss&accuracy: 3872 0.9596 \tvalidation set accuracy: 0.9593 .....................\n",
      " 306 \ttraining set loss&accuracy: 3855 0.9598 \tvalidation set accuracy: 0.9593 .....................\n",
      " 307 \ttraining set loss&accuracy: 3839 0.9596 \tvalidation set accuracy: 0.9593 .....................\n",
      " 308 \ttraining set loss&accuracy: 3823 0.9601 \tvalidation set accuracy: 0.9593 .....................\n",
      " 309 \ttraining set loss&accuracy: 3807 0.9602 \tvalidation set accuracy: 0.9594 .....................\n",
      " 310 \ttraining set loss&accuracy: 3791 0.9601 \tvalidation set accuracy: 0.9596 .....................\n",
      " 311 \ttraining set loss&accuracy: 3776 0.9602 \tvalidation set accuracy: 0.9595 .....................\n",
      " 312 \ttraining set loss&accuracy: 3759 0.9601 \tvalidation set accuracy: 0.9595 .....................\n",
      " 313 \ttraining set loss&accuracy: 3744 0.9600 \tvalidation set accuracy: 0.9597 .....................\n",
      " 314 \ttraining set loss&accuracy: 3728 0.9601 \tvalidation set accuracy: 0.9597 .....................\n",
      " 315 \ttraining set loss&accuracy: 3713 0.9601 \tvalidation set accuracy: 0.9598 .....................\n",
      " 316 \ttraining set loss&accuracy: 3698 0.9600 \tvalidation set accuracy: 0.9598 .....................\n",
      " 317 \ttraining set loss&accuracy: 3682 0.9600 \tvalidation set accuracy: 0.9600 .....................\n",
      " 318 \ttraining set loss&accuracy: 3667 0.9600 \tvalidation set accuracy: 0.9601 .....................\n",
      " 319 \ttraining set loss&accuracy: 3651 0.9600 \tvalidation set accuracy: 0.9602 .....................\n",
      " 320 \ttraining set loss&accuracy: 3636 0.9600 \tvalidation set accuracy: 0.9602 .....................\n",
      " 321 \ttraining set loss&accuracy: 3621 0.9600 \tvalidation set accuracy: 0.9603 .....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 322 \ttraining set loss&accuracy: 3606 0.9600 \tvalidation set accuracy: 0.9602 .....................\n",
      " 323 \ttraining set loss&accuracy: 3591 0.9598 \tvalidation set accuracy: 0.9601 .....................\n",
      " 324 \ttraining set loss&accuracy: 3577 0.9598 \tvalidation set accuracy: 0.9602 .....................\n",
      " 325 \ttraining set loss&accuracy: 3561 0.9600 \tvalidation set accuracy: 0.9602 .....................\n",
      " 326 \ttraining set loss&accuracy: 3547 0.9600 \tvalidation set accuracy: 0.9603 .....................\n",
      " 327 \ttraining set loss&accuracy: 3532 0.9600 \tvalidation set accuracy: 0.9604 .....................\n",
      " 328 \ttraining set loss&accuracy: 3517 0.9600 \tvalidation set accuracy: 0.9605 .....................\n",
      " 329 \ttraining set loss&accuracy: 3503 0.9600 \tvalidation set accuracy: 0.9605 .....................\n",
      " 330 \ttraining set loss&accuracy: 3488 0.9598 \tvalidation set accuracy: 0.9605 .....................\n",
      " 331 \ttraining set loss&accuracy: 3474 0.9598 \tvalidation set accuracy: 0.9604 .....................\n",
      " 332 \ttraining set loss&accuracy: 3459 0.9598 \tvalidation set accuracy: 0.9605 .....................\n",
      " 333 \ttraining set loss&accuracy: 3445 0.9598 \tvalidation set accuracy: 0.9605 .....................\n",
      " 334 \ttraining set loss&accuracy: 3431 0.9598 \tvalidation set accuracy: 0.9605 .....................\n",
      " 335 \ttraining set loss&accuracy: 3417 0.9598 \tvalidation set accuracy: 0.9605 .....................\n",
      " 336 \ttraining set loss&accuracy: 3403 0.9598 \tvalidation set accuracy: 0.9604 .....................\n",
      " 337 \ttraining set loss&accuracy: 3389 0.9598 \tvalidation set accuracy: 0.9603 .....................\n",
      " 338 \ttraining set loss&accuracy: 3374 0.9598 \tvalidation set accuracy: 0.9603 .....................\n",
      " 339 \ttraining set loss&accuracy: 3360 0.9598 \tvalidation set accuracy: 0.9604 .....................\n",
      " 340 \ttraining set loss&accuracy: 3347 0.9599 \tvalidation set accuracy: 0.9604 .....................\n",
      " 341 \ttraining set loss&accuracy: 3333 0.9600 \tvalidation set accuracy: 0.9604 .....................\n",
      " 342 \ttraining set loss&accuracy: 3319 0.9600 \tvalidation set accuracy: 0.9604 .....................\n",
      " 343 \ttraining set loss&accuracy: 3306 0.9600 \tvalidation set accuracy: 0.9603 .....................\n",
      " 344 \ttraining set loss&accuracy: 3292 0.9600 \tvalidation set accuracy: 0.9605 .....................\n",
      " 345 \ttraining set loss&accuracy: 3278 0.9598 \tvalidation set accuracy: 0.9604 .....................\n",
      " 346 \ttraining set loss&accuracy: 3265 0.9600 \tvalidation set accuracy: 0.9604 .....................\n",
      " 347 \ttraining set loss&accuracy: 3252 0.9600 \tvalidation set accuracy: 0.9605 .....................\n",
      " 348 \ttraining set loss&accuracy: 3238 0.9600 \tvalidation set accuracy: 0.9605 .....................\n",
      " 349 \ttraining set loss&accuracy: 3225 0.9598 \tvalidation set accuracy: 0.9605 .....................\n",
      " 350 \ttraining set loss&accuracy: 3211 0.9596 \tvalidation set accuracy: 0.9605 .....................\n",
      " 351 \ttraining set loss&accuracy: 3198 0.9596 \tvalidation set accuracy: 0.9604 .....................\n",
      " 352 \ttraining set loss&accuracy: 3186 0.9596 \tvalidation set accuracy: 0.9605 .....................\n",
      " 353 \ttraining set loss&accuracy: 3172 0.9594 \tvalidation set accuracy: 0.9605 .....................\n",
      " 354 \ttraining set loss&accuracy: 3159 0.9596 \tvalidation set accuracy: 0.9602 .....................\n",
      " 355 \ttraining set loss&accuracy: 3146 0.9593 \tvalidation set accuracy: 0.9602 .....................\n",
      " 356 \ttraining set loss&accuracy: 3133 0.9593 \tvalidation set accuracy: 0.9603 .....................\n",
      " 357 \ttraining set loss&accuracy: 3120 0.9593 \tvalidation set accuracy: 0.9601 .....................\n",
      " 358 \ttraining set loss&accuracy: 3107 0.9595 \tvalidation set accuracy: 0.9601 .....................\n",
      " 359 \ttraining set loss&accuracy: 3095 0.9593 \tvalidation set accuracy: 0.9601 .....................\n",
      " 360 \ttraining set loss&accuracy: 3082 0.9593 \tvalidation set accuracy: 0.9602 .....................\n",
      " 361 \ttraining set loss&accuracy: 3069 0.9595 \tvalidation set accuracy: 0.9602 .....................\n",
      " 362 \ttraining set loss&accuracy: 3057 0.9593 \tvalidation set accuracy: 0.9602 .....................\n",
      " 363 \ttraining set loss&accuracy: 3044 0.9593 \tvalidation set accuracy: 0.9602 .....................\n",
      " 364 \ttraining set loss&accuracy: 3032 0.9593 \tvalidation set accuracy: 0.9602 .....................\n",
      " 365 \ttraining set loss&accuracy: 3019 0.9593 \tvalidation set accuracy: 0.9601 .....................\n",
      " 366 \ttraining set loss&accuracy: 3007 0.9593 \tvalidation set accuracy: 0.9603 .....................\n",
      " 367 \ttraining set loss&accuracy: 2995 0.9591 \tvalidation set accuracy: 0.9603 .....................\n",
      " 368 \ttraining set loss&accuracy: 2982 0.9591 \tvalidation set accuracy: 0.9603 .....................\n",
      " 369 \ttraining set loss&accuracy: 2970 0.9591 \tvalidation set accuracy: 0.9604 .....................\n",
      " 370 \ttraining set loss&accuracy: 2958 0.9591 \tvalidation set accuracy: 0.9605 .....................\n",
      " 371 \ttraining set loss&accuracy: 2946 0.9593 \tvalidation set accuracy: 0.9604 .....................\n",
      " 372 \ttraining set loss&accuracy: 2933 0.9593 \tvalidation set accuracy: 0.9608 .....................\n",
      " 373 \ttraining set loss&accuracy: 2921 0.9593 \tvalidation set accuracy: 0.9607 .....................\n",
      " 374 \ttraining set loss&accuracy: 2909 0.9593 \tvalidation set accuracy: 0.9607 .....................\n",
      " 375 \ttraining set loss&accuracy: 2898 0.9593 \tvalidation set accuracy: 0.9607 .....................\n",
      " 376 \ttraining set loss&accuracy: 2886 0.9593 \tvalidation set accuracy: 0.9608 .....................\n",
      " 377 \ttraining set loss&accuracy: 2873 0.9593 \tvalidation set accuracy: 0.9608 .....................\n",
      " 378 \ttraining set loss&accuracy: 2862 0.9593 \tvalidation set accuracy: 0.9607 .....................\n",
      " 379 \ttraining set loss&accuracy: 2850 0.9593 \tvalidation set accuracy: 0.9607 .....................\n",
      " 380 \ttraining set loss&accuracy: 2839 0.9594 \tvalidation set accuracy: 0.9606 .....................\n",
      " 381 \ttraining set loss&accuracy: 2827 0.9592 \tvalidation set accuracy: 0.9606 .....................\n",
      " 382 \ttraining set loss&accuracy: 2815 0.9594 \tvalidation set accuracy: 0.9607 .....................\n",
      " 383 \ttraining set loss&accuracy: 2803 0.9592 \tvalidation set accuracy: 0.9608 .....................\n",
      " 384 \ttraining set loss&accuracy: 2792 0.9592 \tvalidation set accuracy: 0.9607 .....................\n",
      " 385 \ttraining set loss&accuracy: 2780 0.9590 \tvalidation set accuracy: 0.9606 .....................\n",
      " 386 \ttraining set loss&accuracy: 2769 0.9592 \tvalidation set accuracy: 0.9607 .....................\n",
      " 387 \ttraining set loss&accuracy: 2758 0.9592 \tvalidation set accuracy: 0.9606 .....................\n",
      " 388 \ttraining set loss&accuracy: 2746 0.9592 \tvalidation set accuracy: 0.9606 .....................\n",
      " 389 \ttraining set loss&accuracy: 2735 0.9592 \tvalidation set accuracy: 0.9606 .....................\n",
      " 390 \ttraining set loss&accuracy: 2724 0.9594 \tvalidation set accuracy: 0.9606 .....................\n",
      " 391 \ttraining set loss&accuracy: 2712 0.9593 \tvalidation set accuracy: 0.9605 .....................\n",
      " 392 \ttraining set loss&accuracy: 2702 0.9595 \tvalidation set accuracy: 0.9604 .....................\n",
      " 393 \ttraining set loss&accuracy: 2690 0.9593 \tvalidation set accuracy: 0.9605 .....................\n",
      " 394 \ttraining set loss&accuracy: 2679 0.9593 \tvalidation set accuracy: 0.9605 .....................\n",
      " 395 \ttraining set loss&accuracy: 2668 0.9591 \tvalidation set accuracy: 0.9605 .....................\n",
      " 396 \ttraining set loss&accuracy: 2657 0.9591 \tvalidation set accuracy: 0.9604 .....................\n",
      " 397 \ttraining set loss&accuracy: 2645 0.9591 \tvalidation set accuracy: 0.9606 .....................\n",
      " 398 \ttraining set loss&accuracy: 2635 0.9591 \tvalidation set accuracy: 0.9604 .....................\n",
      " 399 \ttraining set loss&accuracy: 2624 0.9591 \tvalidation set accuracy: 0.9606 .....................\n",
      " 400 \ttraining set loss&accuracy: 2612 0.9591 \tvalidation set accuracy: 0.9604 .....................\n",
      " 401 \ttraining set loss&accuracy: 2602 0.9591 \tvalidation set accuracy: 0.9606 .....................\n",
      " 402 \ttraining set loss&accuracy: 2591 0.9591 \tvalidation set accuracy: 0.9605 .....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 403 \ttraining set loss&accuracy: 2581 0.9591 \tvalidation set accuracy: 0.9605 .....................\n",
      " 404 \ttraining set loss&accuracy: 2570 0.9591 \tvalidation set accuracy: 0.9604 .....................\n",
      " 405 \ttraining set loss&accuracy: 2559 0.9591 \tvalidation set accuracy: 0.9603 .....................\n",
      " 406 \ttraining set loss&accuracy: 2549 0.9593 \tvalidation set accuracy: 0.9603 .....................\n",
      " 407 \ttraining set loss&accuracy: 2538 0.9593 \tvalidation set accuracy: 0.9604 .....................\n",
      " 408 \ttraining set loss&accuracy: 2528 0.9593 \tvalidation set accuracy: 0.9604 .....................\n",
      " 409 \ttraining set loss&accuracy: 2517 0.9593 \tvalidation set accuracy: 0.9603 .....................\n",
      " 410 \ttraining set loss&accuracy: 2507 0.9593 \tvalidation set accuracy: 0.9604 .....................\n",
      " 411 \ttraining set loss&accuracy: 2497 0.9593 \tvalidation set accuracy: 0.9602 .....................\n",
      " 412 \ttraining set loss&accuracy: 2487 0.9593 \tvalidation set accuracy: 0.9604 .....................\n",
      " 413 \ttraining set loss&accuracy: 2476 0.9591 \tvalidation set accuracy: 0.9602 .....................\n",
      " 414 \ttraining set loss&accuracy: 2466 0.9591 \tvalidation set accuracy: 0.9601 .....................\n",
      " 415 \ttraining set loss&accuracy: 2455 0.9591 \tvalidation set accuracy: 0.9601 .....................\n",
      " 416 \ttraining set loss&accuracy: 2445 0.9591 \tvalidation set accuracy: 0.9601 .....................\n",
      " 417 \ttraining set loss&accuracy: 2435 0.9591 \tvalidation set accuracy: 0.9601 .....................\n",
      " 418 \ttraining set loss&accuracy: 2425 0.9593 \tvalidation set accuracy: 0.9601 .....................\n",
      " 419 \ttraining set loss&accuracy: 2415 0.9591 \tvalidation set accuracy: 0.9602 .....................\n",
      " 420 \ttraining set loss&accuracy: 2404 0.9591 \tvalidation set accuracy: 0.9600 .....................\n",
      " 421 \ttraining set loss&accuracy: 2395 0.9591 \tvalidation set accuracy: 0.9599 .....................\n",
      " 422 \ttraining set loss&accuracy: 2385 0.9591 \tvalidation set accuracy: 0.9601 .....................\n",
      " 423 \ttraining set loss&accuracy: 2375 0.9590 \tvalidation set accuracy: 0.9601 .....................\n",
      " 424 \ttraining set loss&accuracy: 2365 0.9590 \tvalidation set accuracy: 0.9600 .....................\n",
      " 425 \ttraining set loss&accuracy: 2355 0.9591 \tvalidation set accuracy: 0.9600 .....................\n",
      " 426 \ttraining set loss&accuracy: 2345 0.9591 \tvalidation set accuracy: 0.9599 .....................\n",
      " 427 \ttraining set loss&accuracy: 2335 0.9591 \tvalidation set accuracy: 0.9599 .....................\n",
      " 428 \ttraining set loss&accuracy: 2326 0.9591 \tvalidation set accuracy: 0.9600 .....................\n",
      " 429 \ttraining set loss&accuracy: 2316 0.9591 \tvalidation set accuracy: 0.9601 .....................\n",
      " 430 \ttraining set loss&accuracy: 2306 0.9591 \tvalidation set accuracy: 0.9599 .....................\n",
      " 431 \ttraining set loss&accuracy: 2296 0.9591 \tvalidation set accuracy: 0.9599 .....................\n",
      " 432 \ttraining set loss&accuracy: 2286 0.9591 \tvalidation set accuracy: 0.9601 .....................\n",
      " 433 \ttraining set loss&accuracy: 2277 0.9591 \tvalidation set accuracy: 0.9600 .....................\n",
      " 434 \ttraining set loss&accuracy: 2267 0.9591 \tvalidation set accuracy: 0.9600 .....................\n",
      " 435 \ttraining set loss&accuracy: 2258 0.9591 \tvalidation set accuracy: 0.9601 .....................\n",
      " 436 \ttraining set loss&accuracy: 2248 0.9591 \tvalidation set accuracy: 0.9600 .....................\n",
      " 437 \ttraining set loss&accuracy: 2239 0.9591 \tvalidation set accuracy: 0.9601 .....................\n",
      " 438 \ttraining set loss&accuracy: 2230 0.9591 \tvalidation set accuracy: 0.9601 .....................\n",
      " 439 \ttraining set loss&accuracy: 2220 0.9591 \tvalidation set accuracy: 0.9602 .....................\n",
      " 440 \ttraining set loss&accuracy: 2211 0.9591 \tvalidation set accuracy: 0.9602 .....................\n",
      " 441 \ttraining set loss&accuracy: 2201 0.9591 \tvalidation set accuracy: 0.9602 .....................\n",
      " 442 \ttraining set loss&accuracy: 2192 0.9591 \tvalidation set accuracy: 0.9602 .....................\n",
      " 443 \ttraining set loss&accuracy: 2182 0.9591 \tvalidation set accuracy: 0.9601 .....................\n",
      " 444 \ttraining set loss&accuracy: 2173 0.9591 \tvalidation set accuracy: 0.9602 .....................\n",
      " 445 \ttraining set loss&accuracy: 2164 0.9591 \tvalidation set accuracy: 0.9602 .....................\n",
      " 446 \ttraining set loss&accuracy: 2155 0.9591 \tvalidation set accuracy: 0.9602 .....................\n",
      " 447 \ttraining set loss&accuracy: 2146 0.9591 \tvalidation set accuracy: 0.9602 .....................\n",
      " 448 \ttraining set loss&accuracy: 2137 0.9591 \tvalidation set accuracy: 0.9602 .....................\n",
      " 449 \ttraining set loss&accuracy: 2128 0.9591 \tvalidation set accuracy: 0.9599 .....................\n",
      " 450 \ttraining set loss&accuracy: 2118 0.9591 \tvalidation set accuracy: 0.9600 .....................\n",
      " 451 \ttraining set loss&accuracy: 2110 0.9591 \tvalidation set accuracy: 0.9599 .....................\n",
      " 452 \ttraining set loss&accuracy: 2101 0.9591 \tvalidation set accuracy: 0.9599 .....................\n",
      " 453 \ttraining set loss&accuracy: 2092 0.9591 \tvalidation set accuracy: 0.9599 .....................\n",
      " 454 \ttraining set loss&accuracy: 2083 0.9591 \tvalidation set accuracy: 0.9600 .....................\n",
      " 455 \ttraining set loss&accuracy: 2074 0.9592 \tvalidation set accuracy: 0.9601 .....................\n",
      " 456 \ttraining set loss&accuracy: 2065 0.9592 \tvalidation set accuracy: 0.9601 .....................\n",
      " 457 \ttraining set loss&accuracy: 2057 0.9592 \tvalidation set accuracy: 0.9601 .....................\n",
      " 458 \ttraining set loss&accuracy: 2048 0.9592 \tvalidation set accuracy: 0.9601 .....................\n",
      " 459 \ttraining set loss&accuracy: 2039 0.9592 \tvalidation set accuracy: 0.9601 .....................\n",
      " 460 \ttraining set loss&accuracy: 2030 0.9590 \tvalidation set accuracy: 0.9602 .....................\n",
      " 461 \ttraining set loss&accuracy: 2022 0.9590 \tvalidation set accuracy: 0.9601 .....................\n",
      " 462 \ttraining set loss&accuracy: 2013 0.9590 \tvalidation set accuracy: 0.9602 .....................\n",
      " 463 \ttraining set loss&accuracy: 2005 0.9590 \tvalidation set accuracy: 0.9601 .....................\n",
      " 464 \ttraining set loss&accuracy: 1996 0.9590 \tvalidation set accuracy: 0.9600 .....................\n",
      " 465 \ttraining set loss&accuracy: 1988 0.9590 \tvalidation set accuracy: 0.9599 .....................\n",
      " 466 \ttraining set loss&accuracy: 1979 0.9590 \tvalidation set accuracy: 0.9600 .....................\n",
      " 467 \ttraining set loss&accuracy: 1971 0.9590 \tvalidation set accuracy: 0.9600 .....................\n",
      " 468 \ttraining set loss&accuracy: 1962 0.9590 \tvalidation set accuracy: 0.9600 .....................\n",
      " 469 \ttraining set loss&accuracy: 1954 0.9590 \tvalidation set accuracy: 0.9600 .....................\n",
      " 470 \ttraining set loss&accuracy: 1946 0.9590 \tvalidation set accuracy: 0.9600 .....................\n",
      " 471 \ttraining set loss&accuracy: 1937 0.9590 \tvalidation set accuracy: 0.9600 .....................\n",
      " 472 \ttraining set loss&accuracy: 1929 0.9590 \tvalidation set accuracy: 0.9600 .....................\n",
      " 473 \ttraining set loss&accuracy: 1921 0.9590 \tvalidation set accuracy: 0.9599 .....................\n",
      " 474 \ttraining set loss&accuracy: 1913 0.9590 \tvalidation set accuracy: 0.9601 .....................\n",
      " 475 \ttraining set loss&accuracy: 1905 0.9590 \tvalidation set accuracy: 0.9603 .....................\n",
      " 476 \ttraining set loss&accuracy: 1897 0.9590 \tvalidation set accuracy: 0.9601 .....................\n",
      " 477 \ttraining set loss&accuracy: 1889 0.9590 \tvalidation set accuracy: 0.9603 .....................\n",
      " 478 \ttraining set loss&accuracy: 1881 0.9589 \tvalidation set accuracy: 0.9602 .....................\n",
      " 479 \ttraining set loss&accuracy: 1873 0.9590 \tvalidation set accuracy: 0.9601 .....................\n",
      " 480 \ttraining set loss&accuracy: 1865 0.9590 \tvalidation set accuracy: 0.9600 .....................\n",
      " 481 \ttraining set loss&accuracy: 1857 0.9590 \tvalidation set accuracy: 0.9601 .....................\n",
      " 482 \ttraining set loss&accuracy: 1849 0.9590 \tvalidation set accuracy: 0.9601 .....................\n",
      " 483 \ttraining set loss&accuracy: 1841 0.9590 \tvalidation set accuracy: 0.9600 .....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 484 \ttraining set loss&accuracy: 1833 0.9590 \tvalidation set accuracy: 0.9599 .....................\n",
      " 485 \ttraining set loss&accuracy: 1825 0.9590 \tvalidation set accuracy: 0.9599 .....................\n",
      " 486 \ttraining set loss&accuracy: 1817 0.9589 \tvalidation set accuracy: 0.9599 .....................\n",
      " 487 \ttraining set loss&accuracy: 1810 0.9590 \tvalidation set accuracy: 0.9597 .....................\n",
      " 488 \ttraining set loss&accuracy: 1802 0.9589 \tvalidation set accuracy: 0.9598 .....................\n",
      " 489 \ttraining set loss&accuracy: 1794 0.9589 \tvalidation set accuracy: 0.9597 .....................\n",
      " 490 \ttraining set loss&accuracy: 1786 0.9589 \tvalidation set accuracy: 0.9596 .....................\n",
      " 491 \ttraining set loss&accuracy: 1779 0.9590 \tvalidation set accuracy: 0.9595 .....................\n",
      " 492 \ttraining set loss&accuracy: 1771 0.9590 \tvalidation set accuracy: 0.9595 .....................\n",
      " 493 \ttraining set loss&accuracy: 1764 0.9590 \tvalidation set accuracy: 0.9595 .....................\n",
      " 494 \ttraining set loss&accuracy: 1756 0.9592 \tvalidation set accuracy: 0.9594 .....................\n",
      " 495 \ttraining set loss&accuracy: 1748 0.9592 \tvalidation set accuracy: 0.9594 .....................\n",
      " 496 \ttraining set loss&accuracy: 1740 0.9592 \tvalidation set accuracy: 0.9594 .....................\n",
      " 497 \ttraining set loss&accuracy: 1733 0.9592 \tvalidation set accuracy: 0.9594 .....................\n",
      " 498 \ttraining set loss&accuracy: 1725 0.9592 \tvalidation set accuracy: 0.9593 .....................\n",
      " 499 \ttraining set loss&accuracy: 1718 0.9592 \tvalidation set accuracy: 0.9593 .....................\n",
      " 500 \ttraining set loss&accuracy: 1710 0.9592 \tvalidation set accuracy: 0.9593 .....................\n",
      " 501 \ttraining set loss&accuracy: 1703 0.9592 \tvalidation set accuracy: 0.9594 .....................\n",
      " 502 \ttraining set loss&accuracy: 1695 0.9592 \tvalidation set accuracy: 0.9593 .....................\n",
      " 503 \ttraining set loss&accuracy: 1688 0.9592 \tvalidation set accuracy: 0.9595 .....................\n",
      " 504 \ttraining set loss&accuracy: 1680 0.9592 \tvalidation set accuracy: 0.9594 .....................\n",
      " 505 \ttraining set loss&accuracy: 1672 0.9592 \tvalidation set accuracy: 0.9594 .....................\n",
      " 506 \ttraining set loss&accuracy: 1666 0.9592 \tvalidation set accuracy: 0.9595 .....................\n",
      " 507 \ttraining set loss&accuracy: 1658 0.9592 \tvalidation set accuracy: 0.9592 .....................\n",
      " 508 \ttraining set loss&accuracy: 1651 0.9592 \tvalidation set accuracy: 0.9594 .....................\n",
      " 509 \ttraining set loss&accuracy: 1644 0.9592 \tvalidation set accuracy: 0.9594 .....................\n",
      " 510 \ttraining set loss&accuracy: 1636 0.9592 \tvalidation set accuracy: 0.9594 .....................\n",
      " 511 \ttraining set loss&accuracy: 1630 0.9592 \tvalidation set accuracy: 0.9595 .....................\n",
      " 512 \ttraining set loss&accuracy: 1622 0.9592 \tvalidation set accuracy: 0.9593 .....................\n",
      " 513 \ttraining set loss&accuracy: 1615 0.9592 \tvalidation set accuracy: 0.9595 .....................\n",
      " 514 \ttraining set loss&accuracy: 1608 0.9592 \tvalidation set accuracy: 0.9593 .....................\n",
      " 515 \ttraining set loss&accuracy: 1601 0.9592 \tvalidation set accuracy: 0.9593 .....................\n",
      " 516 \ttraining set loss&accuracy: 1594 0.9592 \tvalidation set accuracy: 0.9595 .....................\n",
      " 517 \ttraining set loss&accuracy: 1587 0.9592 \tvalidation set accuracy: 0.9594 .....................\n",
      " 518 \ttraining set loss&accuracy: 1580 0.9592 \tvalidation set accuracy: 0.9595 .....................\n",
      " 519 \ttraining set loss&accuracy: 1574 0.9592 \tvalidation set accuracy: 0.9596 .....................\n",
      " 520 \ttraining set loss&accuracy: 1566 0.9592 \tvalidation set accuracy: 0.9593 .....................\n",
      " 521 \ttraining set loss&accuracy: 1559 0.9592 \tvalidation set accuracy: 0.9595 .....................\n",
      " 522 \ttraining set loss&accuracy: 1553 0.9592 \tvalidation set accuracy: 0.9595 .....................\n",
      " 523 \ttraining set loss&accuracy: 1546 0.9592 \tvalidation set accuracy: 0.9596 .....................\n",
      " 524 \ttraining set loss&accuracy: 1539 0.9592 \tvalidation set accuracy: 0.9596 .....................\n",
      " 525 \ttraining set loss&accuracy: 1533 0.9592 \tvalidation set accuracy: 0.9596 .....................\n",
      " 526 \ttraining set loss&accuracy: 1526 0.9592 \tvalidation set accuracy: 0.9597 .....................\n",
      " 527 \ttraining set loss&accuracy: 1519 0.9592 \tvalidation set accuracy: 0.9596 .....................\n",
      " 528 \ttraining set loss&accuracy: 1512 0.9592 \tvalidation set accuracy: 0.9596 .....................\n",
      " 529 \ttraining set loss&accuracy: 1506 0.9592 \tvalidation set accuracy: 0.9597 .....................\n",
      " 530 \ttraining set loss&accuracy: 1500 0.9592 \tvalidation set accuracy: 0.9599 .....................\n",
      " 531 \ttraining set loss&accuracy: 1493 0.9592 \tvalidation set accuracy: 0.9599 .....................\n",
      " 532 \ttraining set loss&accuracy: 1486 0.9592 \tvalidation set accuracy: 0.9600 .....................\n",
      " 533 \ttraining set loss&accuracy: 1480 0.9592 \tvalidation set accuracy: 0.9599 .....................\n",
      " 534 \ttraining set loss&accuracy: 1473 0.9592 \tvalidation set accuracy: 0.9599 .....................\n",
      " 535 \ttraining set loss&accuracy: 1467 0.9592 \tvalidation set accuracy: 0.9599 .....................\n",
      " 536 \ttraining set loss&accuracy: 1461 0.9592 \tvalidation set accuracy: 0.9599 .....................\n",
      " 537 \ttraining set loss&accuracy: 1454 0.9594 \tvalidation set accuracy: 0.9598 .....................\n",
      " 538 \ttraining set loss&accuracy: 1448 0.9592 \tvalidation set accuracy: 0.9599 .....................\n",
      " 539 \ttraining set loss&accuracy: 1441 0.9594 \tvalidation set accuracy: 0.9599 .....................\n",
      " 540 \ttraining set loss&accuracy: 1435 0.9594 \tvalidation set accuracy: 0.9599 .....................\n",
      " 541 \ttraining set loss&accuracy: 1429 0.9594 \tvalidation set accuracy: 0.9599 .....................\n",
      " 542 \ttraining set loss&accuracy: 1423 0.9594 \tvalidation set accuracy: 0.9599 .....................\n",
      " 543 \ttraining set loss&accuracy: 1417 0.9592 \tvalidation set accuracy: 0.9600 .....................\n",
      " 544 \ttraining set loss&accuracy: 1411 0.9592 \tvalidation set accuracy: 0.9599 .....................\n",
      " 545 \ttraining set loss&accuracy: 1404 0.9592 \tvalidation set accuracy: 0.9600 .....................\n",
      " 546 \ttraining set loss&accuracy: 1399 0.9592 \tvalidation set accuracy: 0.9600 .....................\n",
      " 547 \ttraining set loss&accuracy: 1392 0.9592 \tvalidation set accuracy: 0.9599 .....................\n",
      " 548 \ttraining set loss&accuracy: 1386 0.9592 \tvalidation set accuracy: 0.9599 .....................\n",
      " 549 \ttraining set loss&accuracy: 1380 0.9592 \tvalidation set accuracy: 0.9599 .....................\n",
      " 550 \ttraining set loss&accuracy: 1374 0.9592 \tvalidation set accuracy: 0.9600 .....................\n",
      " 551 \ttraining set loss&accuracy: 1368 0.9592 \tvalidation set accuracy: 0.9598 .....................\n",
      " 552 \ttraining set loss&accuracy: 1363 0.9592 \tvalidation set accuracy: 0.9597 .....................\n",
      " 553 \ttraining set loss&accuracy: 1356 0.9592 \tvalidation set accuracy: 0.9597 .....................\n",
      " 554 \ttraining set loss&accuracy: 1350 0.9592 \tvalidation set accuracy: 0.9598 .....................\n",
      " 555 \ttraining set loss&accuracy: 1344 0.9590 \tvalidation set accuracy: 0.9597 .....................\n",
      " 556 \ttraining set loss&accuracy: 1338 0.9590 \tvalidation set accuracy: 0.9597 .....................\n",
      " 557 \ttraining set loss&accuracy: 1333 0.9590 \tvalidation set accuracy: 0.9597 .....................\n",
      " 558 \ttraining set loss&accuracy: 1327 0.9590 \tvalidation set accuracy: 0.9596 .....................\n",
      " 559 \ttraining set loss&accuracy: 1321 0.9590 \tvalidation set accuracy: 0.9597 .....................\n",
      " 560 \ttraining set loss&accuracy: 1315 0.9590 \tvalidation set accuracy: 0.9595 .....................\n",
      " 561 \ttraining set loss&accuracy: 1309 0.9590 \tvalidation set accuracy: 0.9594 .....................\n",
      " 562 \ttraining set loss&accuracy: 1304 0.9590 \tvalidation set accuracy: 0.9594 .....................\n",
      " 563 \ttraining set loss&accuracy: 1298 0.9590 \tvalidation set accuracy: 0.9594 .....................\n",
      " 564 \ttraining set loss&accuracy: 1292 0.9590 \tvalidation set accuracy: 0.9593 .....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 565 \ttraining set loss&accuracy: 1287 0.9590 \tvalidation set accuracy: 0.9595 .....................\n",
      " 566 \ttraining set loss&accuracy: 1281 0.9588 \tvalidation set accuracy: 0.9596 .....................\n",
      " 567 \ttraining set loss&accuracy: 1275 0.9590 \tvalidation set accuracy: 0.9595 .....................\n",
      " 568 \ttraining set loss&accuracy: 1270 0.9588 \tvalidation set accuracy: 0.9596 .....................\n",
      " 569 \ttraining set loss&accuracy: 1264 0.9588 \tvalidation set accuracy: 0.9596 .....................\n",
      " 570 \ttraining set loss&accuracy: 1258 0.9588 \tvalidation set accuracy: 0.9596 .....................\n",
      " 571 \ttraining set loss&accuracy: 1253 0.9588 \tvalidation set accuracy: 0.9596 .....................\n",
      " 572 \ttraining set loss&accuracy: 1248 0.9588 \tvalidation set accuracy: 0.9598 .....................\n",
      " 573 \ttraining set loss&accuracy: 1242 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 574 \ttraining set loss&accuracy: 1237 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 575 \ttraining set loss&accuracy: 1231 0.9588 \tvalidation set accuracy: 0.9598 .....................\n",
      " 576 \ttraining set loss&accuracy: 1226 0.9588 \tvalidation set accuracy: 0.9598 .....................\n",
      " 577 \ttraining set loss&accuracy: 1221 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 578 \ttraining set loss&accuracy: 1215 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 579 \ttraining set loss&accuracy: 1210 0.9586 \tvalidation set accuracy: 0.9600 .....................\n",
      " 580 \ttraining set loss&accuracy: 1204 0.9586 \tvalidation set accuracy: 0.9599 .....................\n",
      " 581 \ttraining set loss&accuracy: 1200 0.9586 \tvalidation set accuracy: 0.9599 .....................\n",
      " 582 \ttraining set loss&accuracy: 1194 0.9586 \tvalidation set accuracy: 0.9598 .....................\n",
      " 583 \ttraining set loss&accuracy: 1189 0.9586 \tvalidation set accuracy: 0.9598 .....................\n",
      " 584 \ttraining set loss&accuracy: 1184 0.9586 \tvalidation set accuracy: 0.9601 .....................\n",
      " 585 \ttraining set loss&accuracy: 1179 0.9586 \tvalidation set accuracy: 0.9600 .....................\n",
      " 586 \ttraining set loss&accuracy: 1173 0.9586 \tvalidation set accuracy: 0.9601 .....................\n",
      " 587 \ttraining set loss&accuracy: 1168 0.9586 \tvalidation set accuracy: 0.9601 .....................\n",
      " 588 \ttraining set loss&accuracy: 1163 0.9586 \tvalidation set accuracy: 0.9602 .....................\n",
      " 589 \ttraining set loss&accuracy: 1158 0.9586 \tvalidation set accuracy: 0.9601 .....................\n",
      " 590 \ttraining set loss&accuracy: 1153 0.9586 \tvalidation set accuracy: 0.9601 .....................\n",
      " 591 \ttraining set loss&accuracy: 1148 0.9586 \tvalidation set accuracy: 0.9601 .....................\n",
      " 592 \ttraining set loss&accuracy: 1143 0.9586 \tvalidation set accuracy: 0.9602 .....................\n",
      " 593 \ttraining set loss&accuracy: 1138 0.9586 \tvalidation set accuracy: 0.9601 .....................\n",
      " 594 \ttraining set loss&accuracy: 1133 0.9586 \tvalidation set accuracy: 0.9600 .....................\n",
      " 595 \ttraining set loss&accuracy: 1128 0.9586 \tvalidation set accuracy: 0.9602 .....................\n",
      " 596 \ttraining set loss&accuracy: 1123 0.9586 \tvalidation set accuracy: 0.9599 .....................\n",
      " 597 \ttraining set loss&accuracy: 1118 0.9586 \tvalidation set accuracy: 0.9599 .....................\n",
      " 598 \ttraining set loss&accuracy: 1114 0.9586 \tvalidation set accuracy: 0.9599 .....................\n",
      " 599 \ttraining set loss&accuracy: 1109 0.9586 \tvalidation set accuracy: 0.9599 .....................\n",
      " 600 \ttraining set loss&accuracy: 1104 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 601 \ttraining set loss&accuracy: 1099 0.9588 \tvalidation set accuracy: 0.9597 .....................\n",
      " 602 \ttraining set loss&accuracy: 1095 0.9588 \tvalidation set accuracy: 0.9598 .....................\n",
      " 603 \ttraining set loss&accuracy: 1090 0.9588 \tvalidation set accuracy: 0.9600 .....................\n",
      " 604 \ttraining set loss&accuracy: 1085 0.9588 \tvalidation set accuracy: 0.9598 .....................\n",
      " 605 \ttraining set loss&accuracy: 1080 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 606 \ttraining set loss&accuracy: 1076 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 607 \ttraining set loss&accuracy: 1071 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 608 \ttraining set loss&accuracy: 1066 0.9588 \tvalidation set accuracy: 0.9598 .....................\n",
      " 609 \ttraining set loss&accuracy: 1062 0.9588 \tvalidation set accuracy: 0.9598 .....................\n",
      " 610 \ttraining set loss&accuracy: 1057 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 611 \ttraining set loss&accuracy: 1053 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 612 \ttraining set loss&accuracy: 1048 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 613 \ttraining set loss&accuracy: 1043 0.9588 \tvalidation set accuracy: 0.9598 .....................\n",
      " 614 \ttraining set loss&accuracy: 1039 0.9588 \tvalidation set accuracy: 0.9598 .....................\n",
      " 615 \ttraining set loss&accuracy: 1035 0.9588 \tvalidation set accuracy: 0.9600 .....................\n",
      " 616 \ttraining set loss&accuracy: 1030 0.9588 \tvalidation set accuracy: 0.9597 .....................\n",
      " 617 \ttraining set loss&accuracy: 1026 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 618 \ttraining set loss&accuracy: 1021 0.9588 \tvalidation set accuracy: 0.9600 .....................\n",
      " 619 \ttraining set loss&accuracy: 1017 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 620 \ttraining set loss&accuracy: 1012 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 621 \ttraining set loss&accuracy: 1008 0.9588 \tvalidation set accuracy: 0.9599 .....................\n",
      " 622 \ttraining set loss&accuracy: 1004 0.9588 \tvalidation set accuracy: 0.9597 .....................\n",
      " 623 \ttraining set loss&accuracy: 999 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 624 \ttraining set loss&accuracy: 995 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 625 \ttraining set loss&accuracy: 990 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 626 \ttraining set loss&accuracy: 986 0.9588 \tvalidation set accuracy: 0.9599 ......................\n",
      " 627 \ttraining set loss&accuracy: 982 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 628 \ttraining set loss&accuracy: 978 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 629 \ttraining set loss&accuracy: 974 0.9586 \tvalidation set accuracy: 0.9599 ......................\n",
      " 630 \ttraining set loss&accuracy: 970 0.9586 \tvalidation set accuracy: 0.9598 ......................\n",
      " 631 \ttraining set loss&accuracy: 965 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 632 \ttraining set loss&accuracy: 961 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 633 \ttraining set loss&accuracy: 957 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 634 \ttraining set loss&accuracy: 953 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 635 \ttraining set loss&accuracy: 949 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 636 \ttraining set loss&accuracy: 945 0.9586 \tvalidation set accuracy: 0.9600 ......................\n",
      " 637 \ttraining set loss&accuracy: 941 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 638 \ttraining set loss&accuracy: 937 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 639 \ttraining set loss&accuracy: 933 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 640 \ttraining set loss&accuracy: 929 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 641 \ttraining set loss&accuracy: 925 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 642 \ttraining set loss&accuracy: 921 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 643 \ttraining set loss&accuracy: 917 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 644 \ttraining set loss&accuracy: 913 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 645 \ttraining set loss&accuracy: 909 0.9588 \tvalidation set accuracy: 0.9596 ......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 646 \ttraining set loss&accuracy: 905 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 647 \ttraining set loss&accuracy: 901 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 648 \ttraining set loss&accuracy: 897 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 649 \ttraining set loss&accuracy: 893 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 650 \ttraining set loss&accuracy: 890 0.9588 \tvalidation set accuracy: 0.9594 ......................\n",
      " 651 \ttraining set loss&accuracy: 886 0.9588 \tvalidation set accuracy: 0.9594 ......................\n",
      " 652 \ttraining set loss&accuracy: 882 0.9588 \tvalidation set accuracy: 0.9595 ......................\n",
      " 653 \ttraining set loss&accuracy: 878 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 654 \ttraining set loss&accuracy: 874 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 655 \ttraining set loss&accuracy: 870 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 656 \ttraining set loss&accuracy: 867 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 657 \ttraining set loss&accuracy: 863 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 658 \ttraining set loss&accuracy: 859 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 659 \ttraining set loss&accuracy: 856 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 660 \ttraining set loss&accuracy: 852 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 661 \ttraining set loss&accuracy: 848 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 662 \ttraining set loss&accuracy: 845 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 663 \ttraining set loss&accuracy: 841 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 664 \ttraining set loss&accuracy: 837 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 665 \ttraining set loss&accuracy: 834 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 666 \ttraining set loss&accuracy: 831 0.9588 \tvalidation set accuracy: 0.9599 ......................\n",
      " 667 \ttraining set loss&accuracy: 827 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 668 \ttraining set loss&accuracy: 823 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 669 \ttraining set loss&accuracy: 820 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 670 \ttraining set loss&accuracy: 816 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 671 \ttraining set loss&accuracy: 813 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 672 \ttraining set loss&accuracy: 809 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 673 \ttraining set loss&accuracy: 806 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 674 \ttraining set loss&accuracy: 803 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 675 \ttraining set loss&accuracy: 799 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 676 \ttraining set loss&accuracy: 796 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 677 \ttraining set loss&accuracy: 792 0.9588 \tvalidation set accuracy: 0.9598 ......................\n",
      " 678 \ttraining set loss&accuracy: 789 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 679 \ttraining set loss&accuracy: 786 0.9588 \tvalidation set accuracy:.............................. 0.9596 \n",
      " 680 \ttraining set loss&accuracy: 782 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 681 \ttraining set loss&accuracy: 779 0.9588 \tvalidation set accuracy: 0.9594 ......................\n",
      " 682 \ttraining set loss&accuracy: 776 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 683 \ttraining set loss&accuracy: 772 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 684 \ttraining set loss&accuracy: 769 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 685 \ttraining set loss&accuracy: 766 0.9586 \tvalidation set accuracy: 0.9595 ......................\n",
      " 686 \ttraining set loss&accuracy: 762 0.9586 \tvalidation set accuracy: 0.9595 ......................\n",
      " 687 \ttraining set loss&accuracy: 759 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 688 \ttraining set loss&accuracy: 756 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 689 \ttraining set loss&accuracy: 753 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 690 \ttraining set loss&accuracy: 750 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 691 \ttraining set loss&accuracy: 746 0.9586 \tvalidation set accuracy: 0.9595 ......................\n",
      " 692 \ttraining set loss&accuracy: 743 0.9586 \tvalidation set accuracy: 0.9595 ......................\n",
      " 693 \ttraining set loss&accuracy: 740 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 694 \ttraining set loss&accuracy: 737 0.9586 \tvalidation set accuracy: 0.9595 ......................\n",
      " 695 \ttraining set loss&accuracy: 734 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 696 \ttraining set loss&accuracy: 731 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 697 \ttraining set loss&accuracy: 728 0.9586 \tvalidation set accuracy: 0.9595 ......................\n",
      " 698 \ttraining set loss&accuracy: 725 0.9588 \tvalidation set accuracy: 0.9593 ......................\n",
      " 699 \ttraining set loss&accuracy: 721 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 700 \ttraining set loss&accuracy: 719 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 701 \ttraining set loss&accuracy: 715 0.9586 \tvalidation set accuracy: 0.9595 ......................\n",
      " 702 \ttraining set loss&accuracy: 712 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 703 \ttraining set loss&accuracy: 709 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 704 \ttraining set loss&accuracy: 706 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 705 \ttraining set loss&accuracy: 703 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 706 \ttraining set loss&accuracy: 700 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 707 \ttraining set loss&accuracy: 698 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 708 \ttraining set loss&accuracy: 695 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 709 \ttraining set loss&accuracy: 692 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 710 \ttraining set loss&accuracy: 689 0.9586 \tvalidation set accuracy: 0.9595 ......................\n",
      " 711 \ttraining set loss&accuracy: 686 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 712 \ttraining set loss&accuracy: 683 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 713 \ttraining set loss&accuracy: 680 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 714 \ttraining set loss&accuracy: 677 0.9588 \tvalidation set accuracy: 0.9595 ......................\n",
      " 715 \ttraining set loss&accuracy: 674 0.9588 \tvalidation set accuracy: 0.9595 ......................\n",
      " 716 \ttraining set loss&accuracy: 671 0.9588 \tvalidation set accuracy: 0.9594 ......................\n",
      " 717 \ttraining set loss&accuracy: 668 0.9588 \tvalidation set accuracy: 0.9594 ......................\n",
      " 718 \ttraining set loss&accuracy: 666 0.9588 \tvalidation set accuracy: 0.9594 ......................\n",
      " 719 \ttraining set loss&accuracy: 663 0.9588 \tvalidation set accuracy: 0.9595 ......................\n",
      " 720 \ttraining set loss&accuracy: 660 0.9588 \tvalidation set accuracy: 0.9594 ......................\n",
      " 721 \ttraining set loss&accuracy: 657 0.9588 \tvalidation set accuracy: 0.9594 ......................\n",
      " 722 \ttraining set loss&accuracy: 655 0.9588 \tvalidation set accuracy: 0.9593 ......................\n",
      " 723 \ttraining set loss&accuracy: 652 0.9588 \tvalidation set accuracy: 0.9593 ......................\n",
      " 724 \ttraining set loss&accuracy: 649 0.9588 \tvalidation set accuracy: 0.9593 ......................\n",
      " 725 \ttraining set loss&accuracy: 646 0.9588 \tvalidation set accuracy: 0.9593 ......................\n",
      " 726 \ttraining set loss&accuracy: 644 0.9588 \tvalidation set accuracy: 0.9594 ......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 727 \ttraining set loss&accuracy: 641 0.9588 \tvalidation set accuracy: 0.9593 ......................\n",
      " 728 \ttraining set loss&accuracy: 638 0.9588 \tvalidation set accuracy: 0.9595 ......................\n",
      " 729 \ttraining set loss&accuracy: 635 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 730 \ttraining set loss&accuracy: 633 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 731 \ttraining set loss&accuracy: 630 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 732 \ttraining set loss&accuracy: 628 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 733 \ttraining set loss&accuracy: 625 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 734 \ttraining set loss&accuracy: 622 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 735 \ttraining set loss&accuracy: 620 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 736 \ttraining set loss&accuracy: 617 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 737 \ttraining set loss&accuracy: 615 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 738 \ttraining set loss&accuracy: 612 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 739 \ttraining set loss&accuracy: 609 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 740 \ttraining set loss&accuracy: 607 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 741 \ttraining set loss&accuracy: 604 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 742 \ttraining set loss&accuracy: 601 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 743 \ttraining set loss&accuracy: 599 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 744 \ttraining set loss&accuracy: 597 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 745 \ttraining set loss&accuracy: 594 0.9590 \tvalidation set accuracy: 0.9596 ......................\n",
      " 746 \ttraining set loss&accuracy: 592 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 747 \ttraining set loss&accuracy: 589 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 748 \ttraining set loss&accuracy: 587 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 749 \ttraining set loss&accuracy: 584 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 750 \ttraining set loss&accuracy: 582 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 751 \ttraining set loss&accuracy: 579 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 752 \ttraining set loss&accuracy: 577 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 753 \ttraining set loss&accuracy: 574 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 754 \ttraining set loss&accuracy: 572 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 755 \ttraining set loss&accuracy: 570 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 756 \ttraining set loss&accuracy: 567 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 757 \ttraining set loss&accuracy: 565 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 758 \ttraining set loss&accuracy: 562 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 759 \ttraining set loss&accuracy: 560 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 760 \ttraining set loss&accuracy: 558 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 761 \ttraining set loss&accuracy: 555 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 762 \ttraining set loss&accuracy: 553 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 763 \ttraining set loss&accuracy: 551 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 764 \ttraining set loss&accuracy: 549 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 765 \ttraining set loss&accuracy: 546 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 766 \ttraining set loss&accuracy: 544 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 767 \ttraining set loss&accuracy: 541 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 768 \ttraining set loss&accuracy: 539 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 769 \ttraining set loss&accuracy: 537 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 770 \ttraining set loss&accuracy: 535 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 771 \ttraining set loss&accuracy: 532 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 772 \ttraining set loss&accuracy: 530 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 773 \ttraining set loss&accuracy: 528 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 774 \ttraining set loss&accuracy: 526 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 775 \ttraining set loss&accuracy: 524 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 776 \ttraining set loss&accuracy: 521 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 777 \ttraining set loss&accuracy: 519 0.9590 \tvalidation set accuracy: 0.9595 ......................\n",
      " 778 \ttraining set loss&accuracy: 517 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 779 \ttraining set loss&accuracy: 515 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 780 \ttraining set loss&accuracy: 513 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 781 \ttraining set loss&accuracy: 511 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 782 \ttraining set loss&accuracy: 509 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 783 \ttraining set loss&accuracy: 506 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 784 \ttraining set loss&accuracy: 504 0.9590 \tvalidation set accuracy: 0.9594 ......................\n",
      " 785 \ttraining set loss&accuracy: 502 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 786 \ttraining set loss&accuracy: 500 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 787 \ttraining set loss&accuracy: 498 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 788 \ttraining set loss&accuracy: 496 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 789 \ttraining set loss&accuracy: 494 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 790 \ttraining set loss&accuracy: 491 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 791 \ttraining set loss&accuracy: 489 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 792 \ttraining set loss&accuracy: 488 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 793 \ttraining set loss&accuracy: 485 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 794 \ttraining set loss&accuracy: 483 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 795 \ttraining set loss&accuracy: 481 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 796 \ttraining set loss&accuracy: 479 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 797 \ttraining set loss&accuracy: 477 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 798 \ttraining set loss&accuracy: 475 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 799 \ttraining set loss&accuracy: 473 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 800 \ttraining set loss&accuracy: 471 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 801 \ttraining set loss&accuracy: 469 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 802 \ttraining set loss&accuracy: 467 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 803 \ttraining set loss&accuracy: 465 0.9590 \tvalidation set accuracy: 0.9591 ......................\n",
      " 804 \ttraining set loss&accuracy: 463 0.9590 \tvalidation set accuracy: 0.9591 ......................\n",
      " 805 \ttraining set loss&accuracy: 461 0.9590 \tvalidation set accuracy: 0.9590 ......................\n",
      " 806 \ttraining set loss&accuracy: 459 0.9590 \tvalidation set accuracy: 0.9591 ......................\n",
      " 807 \ttraining set loss&accuracy: 457 0.9590 \tvalidation set accuracy: 0.9590 ......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 808 \ttraining set loss&accuracy: 455 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 809 \ttraining set loss&accuracy: 453 0.9590 \tvalidation set accuracy: 0.9591 ......................\n",
      " 810 \ttraining set loss&accuracy: 451 0.9590 \tvalidation set accuracy: 0.9593 ......................\n",
      " 811 \ttraining set loss&accuracy: 449 0.9590 \tvalidation set accuracy: 0.9591 ......................\n",
      " 812 \ttraining set loss&accuracy: 447 0.9590 \tvalidation set accuracy: 0.9591 ......................\n",
      " 813 \ttraining set loss&accuracy: 445 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 814 \ttraining set loss&accuracy: 443 0.9590 \tvalidation set accuracy: 0.9591 ......................\n",
      " 815 \ttraining set loss&accuracy: 442 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 816 \ttraining set loss&accuracy: 439 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 817 \ttraining set loss&accuracy: 438 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 818 \ttraining set loss&accuracy: 436 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 819 \ttraining set loss&accuracy: 434 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 820 \ttraining set loss&accuracy: 432 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 821 \ttraining set loss&accuracy: 430 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 822 \ttraining set loss&accuracy: 428 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 823 \ttraining set loss&accuracy: 426 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 824 \ttraining set loss&accuracy: 425 0.9590 \tvalidation set accuracy: 0.9591 ......................\n",
      " 825 \ttraining set loss&accuracy: 423 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 826 \ttraining set loss&accuracy: 421 0.9590 \tvalidation set accuracy: 0.9592 ......................\n",
      " 827 \ttraining set loss&accuracy: 419 0.9590 \tvalidation set accuracy: 0.9590 ......................\n",
      " 828 \ttraining set loss&accuracy: 417 0.9590 \tvalidation set accuracy: 0.9591 ......................\n",
      " 829 \ttraining set loss&accuracy: 416 0.9590 \tvalidation set accuracy: 0.9590 ......................\n",
      " 830 \ttraining set loss&accuracy: 414 0.9590 \tvalidation set accuracy: 0.9591 ......................\n",
      " 831 \ttraining set loss&accuracy: 412 0.9590 \tvalidation set accuracy: 0.9590 ......................\n",
      " 832 \ttraining set loss&accuracy: 410 0.9590 \tvalidation set accuracy: 0.9589 ......................\n",
      " 833 \ttraining set loss&accuracy: 409 0.9590 \tvalidation set accuracy: 0.9590 ......................\n",
      " 834 \ttraining set loss&accuracy: 407 0.9590 \tvalidation set accuracy: 0.9590 ......................\n",
      " 835 \ttraining set loss&accuracy: 405 0.9589 \tvalidation set accuracy: 0.9590 ......................\n",
      " 836 \ttraining set loss&accuracy: 403 0.9589 \tvalidation set accuracy: 0.9589 ......................\n",
      " 837 \ttraining set loss&accuracy: 402 0.9589 \tvalidation set accuracy: 0.9589 ......................\n",
      " 838 \ttraining set loss&accuracy: 400 0.9589 \tvalidation set accuracy: 0.9591 ......................\n",
      " 839 \ttraining set loss&accuracy: 398 0.9589 \tvalidation set accuracy: 0.9591 ......................\n",
      " 840 \ttraining set loss&accuracy: 397 0.9589 \tvalidation set accuracy: 0.9590 ......................\n",
      " 841 \ttraining set loss&accuracy: 395 0.9589 \tvalidation set accuracy: 0.9590 ......................\n",
      " 842 \ttraining set loss&accuracy: 393 0.9589 \tvalidation set accuracy: 0.9590 ......................\n",
      " 843 \ttraining set loss&accuracy: 392 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 844 \ttraining set loss&accuracy: 390 0.9589 \tvalidation set accuracy: 0.9591 ......................\n",
      " 845 \ttraining set loss&accuracy: 388 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 846 \ttraining set loss&accuracy: 387 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 847 \ttraining set loss&accuracy: 385 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 848 \ttraining set loss&accuracy: 383 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 849 \ttraining set loss&accuracy: 382 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 850 \ttraining set loss&accuracy: 380 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 851 \ttraining set loss&accuracy: 379 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 852 \ttraining set loss&accuracy: 377 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 853 \ttraining set loss&accuracy: 376 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 854 \ttraining set loss&accuracy: 374 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 855 \ttraining set loss&accuracy: 372 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 856 \ttraining set loss&accuracy: 371 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 857 \ttraining set loss&accuracy: 369 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 858 \ttraining set loss&accuracy: 368 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 859 \ttraining set loss&accuracy: 366 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 860 \ttraining set loss&accuracy: 365 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 861 \ttraining set loss&accuracy: 363 0.9589 \tvalidation set accuracy: 0.9593 ......................\n",
      " 862 \ttraining set loss&accuracy: 362 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 863 \ttraining set loss&accuracy: 360 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 864 \ttraining set loss&accuracy: 359 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 865 \ttraining set loss&accuracy: 358 0.9589 \tvalidation set accuracy: 0.9593 ......................\n",
      " 866 \ttraining set loss&accuracy: 356 0.9589 \tvalidation set accuracy: 0.9593 ......................\n",
      " 867 \ttraining set loss&accuracy: 354 0.9589 \tvalidation set accuracy: 0.9593 ......................\n",
      " 868 \ttraining set loss&accuracy: 353 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 869 \ttraining set loss&accuracy: 352 0.9589 \tvalidation set accuracy: 0.9593 ......................\n",
      " 870 \ttraining set loss&accuracy: 350 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 871 \ttraining set loss&accuracy: 349 0.9589 \tvalidation set accuracy: 0.9591 ......................\n",
      " 872 \ttraining set loss&accuracy: 347 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 873 \ttraining set loss&accuracy: 346 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 874 \ttraining set loss&accuracy: 345 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 875 \ttraining set loss&accuracy: 343 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 876 \ttraining set loss&accuracy: 342 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 877 \ttraining set loss&accuracy: 341 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 878 \ttraining set loss&accuracy: 339 0.9589 \tvalidation set accuracy: 0.9592 ......................\n",
      " 879 \ttraining set loss&accuracy: 338 0.9589 \tvalidation set accuracy: 0.9593 ......................\n",
      " 880 \ttraining set loss&accuracy: 336 0.9589 \tvalidation set accuracy: 0.9593 ......................\n",
      " 881 \ttraining set loss&accuracy: 335 0.9589 \tvalidation set accuracy: 0.9593 ......................\n",
      " 882 \ttraining set loss&accuracy: 334 0.9589 \tvalidation set accuracy: 0.9593 ......................\n",
      " 883 \ttraining set loss&accuracy: 332 0.9589 \tvalidation set accuracy: 0.9593 ......................\n",
      " 884 \ttraining set loss&accuracy: 331 0.9589 \tvalidation set accuracy: 0.9594 ......................\n",
      " 885 \ttraining set loss&accuracy: 330 0.9589 \tvalidation set accuracy: 0.9593 ......................\n",
      " 886 \ttraining set loss&accuracy: 329 0.9589 \tvalidation set accuracy: 0.9594 ......................\n",
      " 887 \ttraining set loss&accuracy: 327 0.9589 \tvalidation set accuracy: 0.9594 ......................\n",
      " 888 \ttraining set loss&accuracy: 326 0.9589 \tvalidation set accuracy: 0.9594 ......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 889 \ttraining set loss&accuracy: 325 0.9589 \tvalidation set accuracy: 0.9595 ......................\n",
      " 890 \ttraining set loss&accuracy: 323 0.9589 \tvalidation set accuracy: 0.9595 ......................\n",
      " 891 \ttraining set loss&accuracy: 322 0.9589 \tvalidation set accuracy: 0.9594 ......................\n",
      " 892 \ttraining set loss&accuracy: 321 0.9589 \tvalidation set accuracy: 0.9594 ......................\n",
      " 893 \ttraining set loss&accuracy: 320 0.9589 \tvalidation set accuracy: 0.9595 ......................\n",
      " 894 \ttraining set loss&accuracy: 319 0.9589 \tvalidation set accuracy: 0.9595 ......................\n",
      " 895 \ttraining set loss&accuracy: 317 0.9589 \tvalidation set accuracy: 0.9595 ......................\n",
      " 896 \ttraining set loss&accuracy: 316 0.9589 \tvalidation set accuracy: 0.9596 ......................\n",
      " 897 \ttraining set loss&accuracy: 315 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 898 \ttraining set loss&accuracy: 314 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 899 \ttraining set loss&accuracy: 313 0.9588 \tvalidation set accuracy: 0.9595 ......................\n",
      " 900 \ttraining set loss&accuracy: 311 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 901 \ttraining set loss&accuracy: 310 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 902 \ttraining set loss&accuracy: 309 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 903 \ttraining set loss&accuracy: 308 0.9588 \tvalidation set accuracy: 0.9595 ......................\n",
      " 904 \ttraining set loss&accuracy: 307 0.9588 \tvalidation set accuracy: 0.9595 ......................\n",
      " 905 \ttraining set loss&accuracy: 305 0.9588 \tvalidation set accuracy: 0.9595 ......................\n",
      " 906 \ttraining set loss&accuracy: 304 0.9588 \tvalidation set accuracy: 0.9595 ......................\n",
      " 907 \ttraining set loss&accuracy: 303 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 908 \ttraining set loss&accuracy: 302 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 909 \ttraining set loss&accuracy: 301 0.9588 \tvalidation set accuracy: 0.9596 ......................\n",
      " 910 \ttraining set loss&accuracy: 300 0.9588 \tvalidation set accuracy: 0.9595 ......................\n",
      " 911 \ttraining set loss&accuracy: 299 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 912 \ttraining set loss&accuracy: 298 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 913 \ttraining set loss&accuracy: 296 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 914 \ttraining set loss&accuracy: 295 0.9588 \tvalidation set accuracy: 0.9597 ......................\n",
      " 915 \ttraining set loss&accuracy: 294 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 916 \ttraining set loss&accuracy: 293 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 917 \ttraining set loss&accuracy: 292 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 918 \ttraining set loss&accuracy: 291 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 919 \ttraining set loss&accuracy: 290 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 920 \ttraining set loss&accuracy: 289 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 921 \ttraining set loss&accuracy: 288 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 922 \ttraining set loss&accuracy: 287 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 923 \ttraining set loss&accuracy: 286 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 924 \ttraining set loss&accuracy: 285 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 925 \ttraining set loss&accuracy: 284 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 926 \ttraining set loss&accuracy: 283 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 927 \ttraining set loss&accuracy: 282 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 928 \ttraining set loss&accuracy: 281 0.9586 \tvalidation set accuracy: 0.9596 ......................\n",
      " 929 \ttraining set loss&accuracy: 280 0.9586 \tvalidation set accuracy: 0.9597 ......................\n",
      " 930 \ttraining set loss&accuracy: 279 0.9586 \tvalidation set accuracy: 0.9595 ......................\n",
      " 931 \ttraining set loss&accuracy: 277 0.9586 \tvalidation set accuracy: 0.9595 ......................\n",
      " 932 \ttraining set loss&accuracy: 277 0.9586 \tvalidation set accuracy: 0.9595 ......................\n",
      " 933 \ttraining set loss&accuracy: 275 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 934 \ttraining set loss&accuracy: 274 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 935 \ttraining set loss&accuracy: 273 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 936 \ttraining set loss&accuracy: 272 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 937 \ttraining set loss&accuracy: 271 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 938 \ttraining set loss&accuracy: 270 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 939 \ttraining set loss&accuracy: 270 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 940 \ttraining set loss&accuracy: 269 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 941 \ttraining set loss&accuracy: 268 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 942 \ttraining set loss&accuracy: 267 0.9586 \tvalidation set accuracy: 0.9594 ......................\n",
      " 943 \ttraining set loss&accuracy: 266 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 944 \ttraining set loss&accuracy: 265 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 945 \ttraining set loss&accuracy: 264 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 946 \ttraining set loss&accuracy: 263 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 947 \ttraining set loss&accuracy: 262 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 948 \ttraining set loss&accuracy: 261 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 949 \ttraining set loss&accuracy: 260 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 950 \ttraining set loss&accuracy: 259 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 951 \ttraining set loss&accuracy: 258 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 952 \ttraining set loss&accuracy: 257 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 953 \ttraining set loss&accuracy: 256 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 954 \ttraining set loss&accuracy: 255 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 955 \ttraining set loss&accuracy: 255 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 956 \ttraining set loss&accuracy: 254 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 957 \ttraining set loss&accuracy: 253 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 958 \ttraining set loss&accuracy: 252 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 959 \ttraining set loss&accuracy: 251 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 960 \ttraining set loss&accuracy: 250 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 961 \ttraining set loss&accuracy: 249 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 962 \ttraining set loss&accuracy: 248 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 963 \ttraining set loss&accuracy: 248 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 964 \ttraining set loss&accuracy: 247 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 965 \ttraining set loss&accuracy: 246 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 966 \ttraining set loss&accuracy: 245 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 967 \ttraining set loss&accuracy: 244 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 968 \ttraining set loss&accuracy: 243 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 969 \ttraining set loss&accuracy: 243 0.9586 \tvalidation set accuracy: 0.9591 ......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 970 \ttraining set loss&accuracy: 242 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 971 \ttraining set loss&accuracy: 241 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 972 \ttraining set loss&accuracy: 240 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 973 \ttraining set loss&accuracy: 239 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 974 \ttraining set loss&accuracy: 238 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 975 \ttraining set loss&accuracy: 238 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 976 \ttraining set loss&accuracy: 237 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 977 \ttraining set loss&accuracy: 236 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 978 \ttraining set loss&accuracy: 235 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 979 \ttraining set loss&accuracy: 234 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 980 \ttraining set loss&accuracy: 234 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 981 \ttraining set loss&accuracy: 233 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 982 \ttraining set loss&accuracy: 232 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 983 \ttraining set loss&accuracy: 231 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 984 \ttraining set loss&accuracy: 231 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 985 \ttraining set loss&accuracy: 230 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 986 \ttraining set loss&accuracy: 229 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 987 \ttraining set loss&accuracy: 228 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 988 \ttraining set loss&accuracy: 227 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 989 \ttraining set loss&accuracy: 227 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 990 \ttraining set loss&accuracy: 226 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 991 \ttraining set loss&accuracy: 225 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 992 \ttraining set loss&accuracy: 224 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 993 \ttraining set loss&accuracy: 224 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 994 \ttraining set loss&accuracy: 223 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 995 \ttraining set loss&accuracy: 222 0.9586 \tvalidation set accuracy: 0.9593 ......................\n",
      " 996 \ttraining set loss&accuracy: 222 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 997 \ttraining set loss&accuracy: 221 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      " 998 \ttraining set loss&accuracy: 220 0.9586 \tvalidation set accuracy: 0.9591 ......................\n",
      " 999 \ttraining set loss&accuracy: 219 0.9586 \tvalidation set accuracy: 0.9592 ......................\n",
      "--- Duration 0:15:24.326507  ---\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.1 # learning rate\n",
    "L2_regularization_rate = 0.0 # e.g. 0.0, 0.001\n",
    "batch_size = 500\n",
    "assert(N_training_data % batch_size == 0)\n",
    "\n",
    "batches_per_epoch = int(N_training_data / batch_size)\n",
    "print (\"layer_sizes =\", layer_sizes, \"\\t#training data =\", N_training_data, \"\\t#batches_per_epoch =\", batches_per_epoch)\n",
    "assert(batches_per_epoch <= 100 or batches_per_epoch % 100 == 0)\n",
    "\n",
    "def data_augmentation(x, y):\n",
    "    for i in range(batch_size):\n",
    "        degree = np.random.rand() * 60 - 30 # [0, 1) * 60 - 30\n",
    "        #degree = 30\n",
    "        img = x[:, i].reshape((28,28))\n",
    "        img = ndimage.rotate(img, degree)\n",
    "        img = crop_center(img, 28, 28)\n",
    "        x[:, i] = img.reshape(784)\n",
    "    return x, y\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "for epoch in range(1000):\n",
    "    J = 0\n",
    "    training_accuracy = 0\n",
    "    for i in range(batches_per_epoch):\n",
    "        if batches_per_epoch <= 100 or i % int(batches_per_epoch/100) == 0:\n",
    "            sys.stdout.write('.')\n",
    "        \n",
    "        x_batch = x_train[:, i*batch_size:(i+1)*batch_size].copy()\n",
    "        y_batch = y_train[:, i*batch_size:(i+1)*batch_size].copy()\n",
    "        #x_batch, y_batch = data_augmentation(x_batch, y_batch)\n",
    "        \n",
    "        p = forward(x_batch)\n",
    "        \n",
    "        p = np.maximum(p, 1.0e-323) # force saturate\n",
    "        p = np.minimum(p, 1-1.0e-16) # force saturate\n",
    "        J += -1.0 * (np.sum(y_batch*np.log(p) + (1-y_batch)*np.log(1-p))) # cross entropy\n",
    "        for l in range(1, N_layers):\n",
    "            J += L2_regularization_rate * (np.einsum('ij,ij', w[l], w[l]) + np.einsum('ij,ij', b[l], b[l]))\n",
    "        y_ = np.argmax(p, axis=0) # an implicity transpose is applied\n",
    "        training_accuracy += np.minimum(1.0, np.sum(y_ == y_batch) / batch_size)\n",
    "        \n",
    "        dJdw, dJdb = backward(p, y_batch)\n",
    "        for l in range(1, N_layers):\n",
    "            dJdw[l] += L2_regularization_rate * 2.0 * (w[l].T)\n",
    "            dJdb[l] += L2_regularization_rate * 2.0 * (b[l].T)\n",
    "        \n",
    "        for l in range(1, N_layers):\n",
    "            w[l] = w[l] - epsilon * (dJdw[l].T)\n",
    "            b[l] = b[l] - epsilon * (dJdb[l].T)\n",
    "    \n",
    "    training_accuracy = training_accuracy / batches_per_epoch\n",
    "    p = forward(x_valid)\n",
    "    y_ = np.argmax(p, axis=0) # an implicity transpose is applied\n",
    "    validation_accuracy = np.sum(y_ == y_valid) / N_validation_data\n",
    "\n",
    "    print (\"\\r\", epoch, \"\\ttraining set loss&accuracy:\", '%.0f'%J, '%.4f'%training_accuracy, \"\\tvalidation set accuracy:\", '%.4f'%validation_accuracy, \"\")\n",
    "print('--- Duration', datetime.datetime.now() - start_time, ' ---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
